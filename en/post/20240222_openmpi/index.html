

<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

 


      <title>Run Docker containers implementing OpenMPI on multiple nodes - </title>

  <meta name="description" content="Motivation
As previously mentioned in this post, I am moving forward with the goal of running Athena&#43;&#43; on multiple nodes. As a preliminary step, I have attempted to run a Docker container with OpenMPI configured on multiple nodes. I will post a summary of what I have done, as I had some difficulties and it may be helpful to others."><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "akenji\u0027s lab",
    
    "url": "https:\/\/akenji3.github.io\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/akenji3.github.io\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/akenji3.github.io\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/akenji3.github.io\/en\/post\/20240222_openmpi\/",
          "name": "Run docker containers implementing open mpi on multiple nodes"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : ""
  },
  "headline": "Run Docker containers implementing OpenMPI on multiple nodes",
  "description" : "Motivation As previously mentioned in this post, I am moving forward with the goal of running Athena\u002b\u002b on multiple nodes. As a preliminary step, I have attempted to run a Docker container with OpenMPI configured on multiple nodes. I will post a summary of what I have done, as I had some difficulties and it may be helpful to others.\n",
  "inLanguage" : "en",
  "wordCount":  1210 ,
  "datePublished" : "2024-02-22T00:00:00\u002b00:00",
  "dateModified" : "2024-02-22T00:00:00\u002b00:00",
  "image" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
  "keywords" : [ "" ],
  "mainEntityOfPage" : "https:\/\/akenji3.github.io\/en\/post\/20240222_openmpi\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/akenji3.github.io\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>


<meta property="og:title" content="Run Docker containers implementing OpenMPI on multiple nodes" />
<meta property="og:description" content="Motivation
As previously mentioned in this post, I am moving forward with the goal of running Athena&#43;&#43; on multiple nodes. As a preliminary step, I have attempted to run a Docker container with OpenMPI configured on multiple nodes. I will post a summary of what I have done, as I had some difficulties and it may be helpful to others.">
<meta property="og:image" content="https://akenji3.github.io/img/avatar-icon.png" />
<meta property="og:url" content="https://akenji3.github.io/en/post/20240222_openmpi/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="akenji&#39;s lab" />

  <meta name="twitter:title" content="Run Docker containers implementing OpenMPI on multiple nodes" />
  <meta name="twitter:description" content="Motivation
As previously mentioned in this post, I am moving forward with the goal of running Athena&#43;&#43; on multiple nodes. As a preliminary step, I have attempted to run a Docker container with OpenMPI â€¦">
  <meta name="twitter:image" content="https://akenji3.github.io/img/avatar-icon.png" />
  <meta name="twitter:card" content="summary_large_image" />
  <link href='https://akenji3.github.io/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.147.1">
  <link rel="alternate" href="https://akenji3.github.io/en/index.xml" type="application/rss+xml" title="akenji&#39;s lab"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css" integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.6.0/css/all.css" integrity="sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"><link rel="stylesheet" href="https://akenji3.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://akenji3.github.io/css/highlight.min.css" /><link rel="stylesheet" href="https://akenji3.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">

      <script async src="https://www.googletagmanager.com/gtag/js?id=G-TGXWYJXF48"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TGXWYJXF48');
        }
      </script>
  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://akenji3.github.io/en/">akenji&#39;s lab</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/en/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/en/page/about/">About</a>
            </li>
          
        
          
            <li>
              <a title="Categories" href="/en/categories">Categories</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/en/tags">Tags</a>
            </li>
          
        

        
          
            <li>
              
                
                  <a href="https://akenji3.github.io/post/20240222_openmpi/">ja</a>
                
              
            </li>
          
        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="akenji&#39;s lab" href="https://akenji3.github.io/en/">
            <img class="avatar-img" src="https://akenji3.github.io/img/avatar-icon.png" alt="akenji&#39;s lab" />
           
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Run Docker containers implementing OpenMPI on multiple nodes</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on February 22, 2024
  
  
  
  
    
      &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;
    
  
  &nbsp;&bull;&nbsp;Other languages: <a href="https://akenji3.github.io/post/20240222_openmpi/" lang="ja">ja</a>
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <h2 id="motivation">Motivation</h2>
<p>As previously mentioned in <a href="https://akenji3.github.io/en/post/20240203_athena&#43;&#43;_en/">this post</a>, I am moving forward with the goal of running Athena++ on multiple nodes. As a preliminary step, I have attempted to run a Docker container with OpenMPI configured on multiple nodes. I will post a summary of what I have done, as I had some difficulties and it may be helpful to others.</p>
<h2 id="sources">Sources.</h2>
<ol>
<li><a href="https://akenji3.github.io/en/post/20231014_horovodindocker_en/">Try Horovod in Docker</a> My own article posted a few months ago. Horovod also uses OpenMPI, and in doing so, without a password. I learned how to connect to OpenMPI without a password in that case.</li>
<li><a href="https://horovod.readthedocs.io/en/latest/docker_include.html">Horovod in Docker</a> The original manual which I also referred to in the above article.</li>
<li><a href="https://www2.yukawa.kyoto-u.ac.jp/~koudai.sugimoto/dokuwiki/doku.php?id=%E8%87%AA%E4%BD%9C%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E8%A8%88%E7%AE%97%E6%A9%9F:mpi%E3%81%AB%E3%82%88%E3%82%8B%E4%B8%A6%E5%88%97%E8%A8%88%E7%AE%97">Parallel Computing with mpi</a> The sample program from this page was adapted. This page also describes how to use ssh for node-to-node communication without password when using OpenMPI.</li>
<li><a href="https://horovod.readthedocs.io/en/latest/mpi_include.html">Horovod with MPI</a> This page describes how to specify the ssh port on the mpirun command line, which was the most difficult part of this project.</li>
<li><a href="https://www.open-mpi.org/doc/current/man1/mpirun.1.php">mpirun(1) man page (verison 4.1.6)</a> I referred to this page when checking the mpirun command line description.</li>
</ol>
<h2 id="procedure">Procedure</h2>
<h4 id="creating-a-docker-container">Creating a Docker container</h4>
<p>As you can see in the following Dockerfile, ssh and openmpi were installed from Ubuntu 22.04 packages. openssh is 8.9p1 and openmpi is 4.1.2. libopenmpi-dev must be installed, If libopenmpi-dev is not installed, the error message &ldquo;mpi.h: No such file or directory&rdquo; will appear when compiling with mpicc.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-dockerfile" data-lang="dockerfile"><span class="line"><span class="cl"><span class="c"># Based on the Dockefile for creating a Docker image that JupyterLab can use,</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># Create a Docker container that can be used for athena++ development and execution.</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># Based on the latest version of ubuntu 22.04.</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">FROM</span><span class="s"> ubuntu:jammy-20240111</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># Set bash as the default shell</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">ENV</span> <span class="nv">SHELL</span><span class="o">=</span>/bin/bash<span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># Build with some basic utilities</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">RUN</span> apt update <span class="o">&amp;&amp;</span> apt install -y <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        build-essential <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    python3-pip apt-utils vim <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    git git-lfs <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    curl unzip wget gnuplot <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        openmpi-bin libopenmpi-dev <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        openssh-client openssh-server<span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># alias python=&#39;python3&#39;</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">RUN</span> ln -s /usr/bin/python3 /usr/bin/python<span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># install python package to need</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">RUN</span> pip install -U pip setuptools <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        <span class="o">&amp;&amp;</span> pip install numpy scipy h5py mpmath<span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># The following stuff is derived for horovod in docker.</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># Allow OpenSSH to talk to containers without asking for confirmation</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">RUN</span> mkdir -p /var/run/sshd<span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">RUN</span> cat /etc/ssh/ssh_config <span class="p">|</span> grep -v StrictHostKeyChecking &gt; /etc/ssh/ssh_config.new <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    <span class="nb">echo</span> <span class="s2">&#34;    StrictHostKeyChecking no&#34;</span> &gt;&gt; /etc/ssh/ssh_config.new <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    mv /etc/ssh/ssh_config.new /etc/ssh/ssh_config<span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># --allow-run-as-root</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">ENV</span> <span class="nv">OMPI_ALLOW_RUN_AS_ROOT</span><span class="o">=</span><span class="m">1</span>
</span></span><span class="line"><span class="cl"><span class="k">ENV</span> <span class="nv">OMPI_ALLOW_RUN_AS_ROOT_CONFIRM</span><span class="o">=</span><span class="m">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># Create a working directory</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">WORKDIR</span><span class="s"> /workdir</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="c"># command prompt</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">CMD</span> <span class="p">[</span><span class="s2">&#34;/bin/bash&#34;</span><span class="p">]</span><span class="err">
</span></span></span></code></pre></div><p>The part of modifying /etc/ssh/ssh_config was taken from the Dockerfile in Horovod in Docker.</p>
<p>I also specified the environment variables in the Dockerfile when running openMPI as root. Without this part, starting as root (in a Docker container) would result in the following message.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">--------------------------------------------------------------------------
</span></span><span class="line"><span class="cl">mpirun has detected an attempt to run as root.
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Running as root is *strongly* discouraged as any mistake <span class="o">(</span>e.g., in
</span></span><span class="line"><span class="cl">defining TMPDIR<span class="o">)</span> or bug can result in catastrophic damage to the OS
</span></span><span class="line"><span class="cl">file system, leaving your system in an unusable state.
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">We strongly suggest that you run mpirun as a non-root user.
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">You can override this protection by adding the --allow-run-as-root option
</span></span><span class="line"><span class="cl">to the cmd line or by setting two environment variables in the following way:
</span></span><span class="line"><span class="cl">the variable <span class="nv">OMPI_ALLOW_RUN_AS_ROOT</span><span class="o">=</span><span class="m">1</span> to indicate the desire to override this
</span></span><span class="line"><span class="cl">protection, and <span class="nv">OMPI_ALLOW_RUN_AS_ROOT_CONFIRM</span><span class="o">=</span><span class="m">1</span> to confirm the choice and
</span></span><span class="line"><span class="cl">add one more layer of certainty that you want to <span class="k">do</span> so.
</span></span><span class="line"><span class="cl">We reiterate our advice against doing so - please proceed at your own risk.
</span></span><span class="line"><span class="cl">--------------------------------------------------------------------------
</span></span></code></pre></div><p>The following steps were used to build the container image.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo docker build -t openssh ./
</span></span></code></pre></div><h4 id="execution-environment">Execution Environment</h4>
<p>Here is a brief description of the execution environment.</p>
<h5 id="primary">Primary</h5>
<p>Under /ext/nfs/ssh on the primary node (hostname: europe), id_rsa.pub created by ssh-keygen is appended to authorized_keys and stored. The permission of authorized_keys must be 600.</p>
<p>The /ext/nfs directory including /ext/nfs/ssh and /ext/nfs/athena++ created in <a href="https://akenji3.github.io/en/post/20240203_athena&#43;&#43;_en/">this article</a> is NFS mounted from other nodes.</p>
<p>The program for testing is placed in /ext/nfs/athena++/tmp, which is NFS-mounted and accessible from other nodes.</p>
<p>The container created is started as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">sudo docker run -it --rm --net<span class="o">=</span>host <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>-v /ext/nfs/ssh:/root/.ssh <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>-v /ext/nfs/athena++:/workdir <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>openmpi:latest
</span></span></code></pre></div><h5 id="secondary">Secondary</h5>
<p>The following line is added to /etc/fstab on the secondary node (hostname: ganymede). This mounts /ext/nfs on the Primary node as /mnt/nfs2, where xxx.xxx.xx.xx.xx is the IP address of the primary node.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">xxx.xxx.xx.xx:/ext/nfs	/mnt/nfs2	nfs
</span></span></code></pre></div><p>On the secondary node, the container is started as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">sudo docker run -it --rm --net<span class="o">=</span>host <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>-v /mnt/nfs2/ssh:/root/.ssh <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>-v /mnt/nfs2/athena++:/workdir <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>openmpi:latest
</span></span></code></pre></div><p>For both primary and secondary nodes, /etc/hosts contains the IP adress and hostname of all connected nodes. When starting the container, &ndash;net=host is used, so the network of the physical machine is transparent to the container.</p>
<h5 id="compile-the-sample-program">Compile the sample program</h5>
<p>Create the following sample program (hello.c) in /ext/nfs/athena++/tmp on the primary node in advance.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;mpi.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span> 
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span> <span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]</span> <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span>     <span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">len</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">char</span>    <span class="n">name</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">    <span class="nf">MPI_Init</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">MPI_Comm_rank</span><span class="p">(</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">rank</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">MPI_Comm_size</span><span class="p">(</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">size</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">MPI_Get_processor_name</span><span class="p">(</span> <span class="n">name</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">len</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">name</span><span class="p">[</span><span class="n">len</span><span class="p">]</span> <span class="o">=</span> <span class="sc">&#39;\0&#39;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">    <span class="nf">printf</span><span class="p">(</span> <span class="s">&#34;Hello world: rank %d of %d running on %s</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">name</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">    <span class="nf">MPI_Finalize</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>Start the container, move to tmp, and compile the sample program.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># pwd</span>
</span></span><span class="line"><span class="cl">/workdir/tmp
</span></span><span class="line"><span class="cl"><span class="c1"># mpicc -o hello hello.c</span>
</span></span></code></pre></div><p>First, let&rsquo;s run it on the Primary node only.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># mpirun -n 4 ./hello</span>
</span></span><span class="line"><span class="cl">Authorization required, but no authorization protocol specified
</span></span><span class="line"><span class="cl">Authorization required, but no authorization protocol specified
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">1</span> of <span class="m">4</span> running on europe
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">2</span> of <span class="m">4</span> running on europe
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">3</span> of <span class="m">4</span> running on europe
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">0</span> of <span class="m">4</span> running on europe
</span></span></code></pre></div><h4 id="run-the-sample-program-on-two-nodes">Run the sample program on two nodes</h4>
<h5 id="secondary-1">Secondary</h5>
<p>Start the container on the secondary node and start sshd as follows. The port number is 12345, the same as in Horovod in Docker.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># /usr/sbin/sshd -p 12345</span>
</span></span></code></pre></div><p>Now, create a list of machines to be connected to mpi in host.txt.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># cat hosts.txt</span>
</span></span><span class="line"><span class="cl">europe
</span></span><span class="line"><span class="cl">ganymede
</span></span></code></pre></div><p>Then, execute the following.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># mpirun -hostfile hosts.txt -mca plm_rsh_args &#34;-p 12345&#34; -n 8 ./hello</span>
</span></span><span class="line"><span class="cl">Authorization required, but no authorization protocol specified
</span></span><span class="line"><span class="cl">Authorization required, but no authorization protocol specified
</span></span><span class="line"><span class="cl">Authorization required, but no authorization protocol specified
</span></span><span class="line"><span class="cl">Authorization required, but no authorization protocol specified
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">2</span> of <span class="m">8</span> running on europe
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">3</span> of <span class="m">8</span> running on europe
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">0</span> of <span class="m">8</span> running on europe
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">1</span> of <span class="m">8</span> running on europe
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">5</span> of <span class="m">8</span> running on ganymede
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">6</span> of <span class="m">8</span> running on ganymede
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">7</span> of <span class="m">8</span> running on ganymede
</span></span><span class="line"><span class="cl">Hello world: rank <span class="m">4</span> of <span class="m">8</span> running on ganymede
</span></span></code></pre></div><p>I had a hard time getting to the above command line &ldquo;-mca plm_rsh_args &ldquo;-p 12345&quot;&rdquo;.</p>
<p>In Horovod in Docker, the port number was specified in the command line of horovodrun, so I was looking for some way to do it and came across source 4.</p>
<h2 id="the-future">The future</h2>
<p>As mentioned above, we can now launch docker containers on multiple nodes and distribute the programs in the containers. In the future, I would like to perform distributed processing with MPI in Athena++. Before that, I would like to investigate the performance of distributed processing with OpenMPI.</p>
<p>The experience with Horovod in Docker was very useful this time.</p>

        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240222_openmpi%2f&amp;text=Run%20Docker%20containers%20implementing%20OpenMPI%20on%20multiple%20nodes&amp;via=" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240222_openmpi%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240222_openmpi%2f&amp;title=Run%20Docker%20containers%20implementing%20OpenMPI%20on%20multiple%20nodes" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240222_openmpi%2f&amp;title=Run%20Docker%20containers%20implementing%20OpenMPI%20on%20multiple%20nodes" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240222_openmpi%2f&amp;title=Run%20Docker%20containers%20implementing%20OpenMPI%20on%20multiple%20nodes" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240222_openmpi%2f&amp;description=Run%20Docker%20containers%20implementing%20OpenMPI%20on%20multiple%20nodes" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://akenji3.github.io/en/post/20240211_athena_tutorial2-3/" data-toggle="tooltip" data-placement="top" title="Run the Athena&#43;&#43; tutorial">&larr; Previous Post</a>
            </li>
          
          
            <li class="next">
              <a href="https://akenji3.github.io/en/post/20240223_himenobenchmpi/" data-toggle="tooltip" data-placement="top" title="easuring OpenMPI performance using the HIMENO benchmark">Next Post &rarr;</a>
            </li>
          
        </ul>
      


      

    </div>
  </div>
</div>

      <footer>
  <div class="container">
    
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
          
          
          
        </ul>
        <p class="credits copyright text-muted">
          

          &nbsp;&bull;&nbsp;&copy;
          
            2026
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://akenji3.github.io/en/">akenji&#39;s lab</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.147.1</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js" integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

<script src="https://akenji3.github.io/js/main.js"></script>
<script src="https://akenji3.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://akenji3.github.io/js/load-photoswipe.js"></script>










    
  </body>
</html>

