

<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

 


      <title>Using LLM based on DeepSeek-R1-Distill-Qwen-14B/32B with additional Japanese language training - </title>

  <meta name="description" content="Motivation
I have been studying PINNs and related OpenFOAM for a while, but yesterday there was a big news in LLM area and I decided to use Deep Seek-R1 which had an impact not only on LLM area but also on stock prices. Since I could not use it as it is in my environment, I used a compacted LLM with quantization.
This time, I used Ollama and Open WebUI to use the quantized model from a browser, and I will summarize the contents."><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "akenji\u0027s lab",
    
    "url": "https:\/\/akenji3.github.io\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/akenji3.github.io\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/akenji3.github.io\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/akenji3.github.io\/en\/post\/20250128_deepseek-ca\/",
          "name": "Using llm based on deep seek r1 distill qwen 14 b 32 b with additional japanese language training"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : ""
  },
  "headline": "Using LLM based on DeepSeek-R1-Distill-Qwen-14B\/32B with additional Japanese language training",
  "description" : "Motivation I have been studying PINNs and related OpenFOAM for a while, but yesterday there was a big news in LLM area and I decided to use Deep Seek-R1 which had an impact not only on LLM area but also on stock prices. Since I could not use it as it is in my environment, I used a compacted LLM with quantization.\nThis time, I used Ollama and Open WebUI to use the quantized model from a browser, and I will summarize the contents.\n",
  "inLanguage" : "en",
  "wordCount":  722 ,
  "datePublished" : "2025-01-28T00:00:00\u002b00:00",
  "dateModified" : "2025-01-28T00:00:00\u002b00:00",
  "image" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
  "keywords" : [ "" ],
  "mainEntityOfPage" : "https:\/\/akenji3.github.io\/en\/post\/20250128_deepseek-ca\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/akenji3.github.io\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>


<meta property="og:title" content="Using LLM based on DeepSeek-R1-Distill-Qwen-14B/32B with additional Japanese language training" />
<meta property="og:description" content="Motivation
I have been studying PINNs and related OpenFOAM for a while, but yesterday there was a big news in LLM area and I decided to use Deep Seek-R1 which had an impact not only on LLM area but also on stock prices. Since I could not use it as it is in my environment, I used a compacted LLM with quantization.
This time, I used Ollama and Open WebUI to use the quantized model from a browser, and I will summarize the contents.">
<meta property="og:image" content="https://akenji3.github.io/img/avatar-icon.png" />
<meta property="og:url" content="https://akenji3.github.io/en/post/20250128_deepseek-ca/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="akenji&#39;s lab" />

  <meta name="twitter:title" content="Using LLM based on DeepSeek-R1-Distill-Qwen-14B/32B with additional …" />
  <meta name="twitter:description" content="Motivation
I have been studying PINNs and related OpenFOAM for a while, but yesterday there was a big news in LLM area and I decided to use Deep Seek-R1 which had an impact not only on LLM area but …">
  <meta name="twitter:image" content="https://akenji3.github.io/img/avatar-icon.png" />
  <meta name="twitter:card" content="summary_large_image" />
  <link href='https://akenji3.github.io/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.147.1">
  <link rel="alternate" href="https://akenji3.github.io/en/index.xml" type="application/rss+xml" title="akenji&#39;s lab"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css" integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.6.0/css/all.css" integrity="sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"><link rel="stylesheet" href="https://akenji3.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://akenji3.github.io/css/highlight.min.css" /><link rel="stylesheet" href="https://akenji3.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">

      <script async src="https://www.googletagmanager.com/gtag/js?id=G-TGXWYJXF48"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TGXWYJXF48');
        }
      </script>
  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://akenji3.github.io/en/">akenji&#39;s lab</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/en/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/en/page/about/">About</a>
            </li>
          
        
          
            <li>
              <a title="Categories" href="/en/categories">Categories</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/en/tags">Tags</a>
            </li>
          
        

        
          
            <li>
              
                
                  <a href="https://akenji3.github.io/post/20250128_deepseek-ca/">ja</a>
                
              
            </li>
          
        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="akenji&#39;s lab" href="https://akenji3.github.io/en/">
            <img class="avatar-img" src="https://akenji3.github.io/img/avatar-icon.png" alt="akenji&#39;s lab" />
           
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Using LLM based on DeepSeek-R1-Distill-Qwen-14B/32B with additional Japanese language training</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on January 28, 2025
  
  
  
  
    
      &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;
    
  
  &nbsp;&bull;&nbsp;Other languages: <a href="https://akenji3.github.io/post/20250128_deepseek-ca/" lang="ja">ja</a>
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <h2 id="motivation">Motivation</h2>
<p>I have been studying PINNs and related OpenFOAM for a while, but yesterday there was a big news in LLM area and I decided to use Deep Seek-R1 which had an impact not only on LLM area but also on stock prices. Since I could not use it as it is in my environment, I used a compacted LLM with quantization.</p>
<p>This time, I used Ollama and Open WebUI to use the quantized model from a browser, and I will summarize the contents.</p>
<h2 id="sources">Sources</h2>
<ol>
<li><a href="https://ascii.jp/elem/000/004/247/4247681/">Impact of DeepSeek-R1, the Chinese AI that surpasses ChatGPT</a> - from ascii.jp. Cited as an example in an article on DeepSeek-R1.</li>
<li><a href="https://x.com/CyberAgent_PR/status/1883783524836413468?mx=2">Announcement from CyberAgent</a> - An announcement from CyberAgent that they have released an LLM based on DeepSeek-R1-Distill-Qwen-14B/32B with additional training on Japanese data.</li>
<li><a href="https://huggingface.co/mmnga/cyberagent-DeepSeek-R1-Distill-Qwen-14B-Japanese-gguf">mmnga/cyberagent-DeepSeek-R1-Distill-Qwen-14B-japanese-gguf</a> - Quantized model of the above CyberAgent version, published on HugginFace.</li>
<li><a href="https://akenji3.github.io/en/post/20241123_openwebui/">Conversing with ollama&rsquo;s LLM using Open WebUI as a front end</a> - I put this together two months ago, but I forgot all about it and had a hard time remembering it. Open WebUI provides a good connection between the Ollama server and the web browser.</li>
<li><a href="https://akenji3.github.io/en/post/20241122_ollama/">Using ollama to run LLM in a local environment</a> - This is an article from the day before the above post, about running Ollama with Docker.</li>
</ol>
<h2 id="procedure">Procedure</h2>
<h4 id="download-the-model-from">Download the model from</h4>
<p>The 4-bit “Q 4_K_M”, a quantization model published in source 3, was downloaded using the following command.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ wget https://huggingface.co/mmnga/cyberagent-DeepSeek-R1-Distill-Qwen-14B-Japanese-gguf/resolve/main/cyberagent-DeepSeek-R1-Distill-Qwen-14B-Japanese-Q4_K_M.gguf
</span></span></code></pre></div><h4 id="embedding-into-the-ollama-server">Embedding into the Ollama server</h4>
<p>First, start ollama as indicated in “Creating docker-compose.yml” in Resource 5.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ sudo docker compose up -d
</span></span></code></pre></div><p>Next, enter the OLLAMA container started above, as described in “Downloading and Executing (the) LLM Model”.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ sudo docker <span class="nb">exec</span> -it ollama /bin/bash
</span></span></code></pre></div><p>The following is an operation within a container.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="c1"># cd /root/.ollama</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ls -l</span>
</span></span><span class="line"><span class="cl">total <span class="m">8777476</span>
</span></span><span class="line"><span class="cl">-rw-rw-r-- <span class="m">1</span> <span class="m">1000</span> <span class="m">1000</span>         <span class="m">68</span> Jan <span class="m">28</span> 05:20 Modelfile
</span></span><span class="line"><span class="cl">-rw-rw-r-- <span class="m">1</span> <span class="m">1000</span> <span class="m">1000</span> <span class="m">8988110464</span> Jan <span class="m">28</span> 05:19 cyberagent-DeepSeek-R1-Distill-Qwen-14B-Japanese-Q4_K_M.gguf
</span></span><span class="line"><span class="cl"><span class="c1"># cat Modelfile</span>
</span></span><span class="line"><span class="cl">FROM ./cyberagent-DeepSeek-R1-Distill-Qwen-14B-Japanese-Q4_K_M.gguf
</span></span></code></pre></div><p>Prepare the downloaded model (.ggu file) and Modelfile as described above so that they can be referenced from the container. When you are ready to this point, use the following command to incorporate them into the ollama server.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="c1"># ollama create cyberagent-DS-14b-japanese -f Modelfile</span>
</span></span></code></pre></div><p>For the incorporation part, see also “Incorporating a gguf file as a model” in Source 5.</p>
<h4 id="launch-open-webui">Launch Open WebUI</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ ls -l
</span></span><span class="line"><span class="cl">drwxrwxr-x <span class="m">5</span> kenji kenji <span class="m">4096</span> 11月 <span class="m">23</span> 11:19 data
</span></span><span class="line"><span class="cl">-rw-rw-r-- <span class="m">1</span> kenji kenji  <span class="m">243</span> 11月 <span class="m">26</span> 08:33 docker-compose.yml
</span></span><span class="line"><span class="cl">$ cat docker-compose.yml
</span></span><span class="line"><span class="cl">services:
</span></span><span class="line"><span class="cl">  open-webui:
</span></span><span class="line"><span class="cl">    image: ghcr.io/open-webui/open-webui:main
</span></span><span class="line"><span class="cl">    container_name: open-webui
</span></span><span class="line"><span class="cl">    environment:
</span></span><span class="line"><span class="cl">      - <span class="nv">OLLAMA_BASE_URL</span><span class="o">=</span>http://192.168.11.4:11434
</span></span><span class="line"><span class="cl">    volumes:
</span></span><span class="line"><span class="cl">      - ./data:/app/backend/data
</span></span><span class="line"><span class="cl">    ports:
</span></span><span class="line"><span class="cl">      - 3000:8080
</span></span><span class="line"><span class="cl">$ sudo docker compose up -d
</span></span></code></pre></div><p>For the part about starting Open WebUI, please also refer to “Starting Open WebUI” in Information Source 4.</p>
<h4 id="connecting-from-a-web-browser">Connecting from a Web browser</h4>
<p>Since the Ollama server and Open WebUI have already been started up, enter “http://192.168.11.8:3000/” from the browser at hand, and the Open WebUI startup screen will appear. After entering your name, e-mail address, and password, you will be prompted with a screen that accepts questions.</p>
<p>Once connected, change the LLM model in the upper left portion of the screen to ask a question. The following is an excerpt of the answer section.</p>
<p><img src="/images/20250128_DeepSeek-CA/20250128_Browser.png" alt="Browser"></p>
<h2 id="summary">Summary</h2>
<p>I was surprised by the amount of answers to my questions, but when I threw other questions, the answers were relatively compact.</p>
<p>I tried the Japanese version of the popular DeepSeek-R1 Cyber Agent quantized model, using the Ollama and Open WebUI systems I had built up to 2 months ago, but I had forgotten many things, such as how to incorporate them into the model and the startup procedure, so it helped that I had summarized them in the past. It helped me a lot.</p>

        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20250128_deepseek-ca%2f&amp;text=Using%20LLM%20based%20on%20DeepSeek-R1-Distill-Qwen-14B%2f32B%20with%20additional%20Japanese%20language%20training&amp;via=" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20250128_deepseek-ca%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20250128_deepseek-ca%2f&amp;title=Using%20LLM%20based%20on%20DeepSeek-R1-Distill-Qwen-14B%2f32B%20with%20additional%20Japanese%20language%20training" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20250128_deepseek-ca%2f&amp;title=Using%20LLM%20based%20on%20DeepSeek-R1-Distill-Qwen-14B%2f32B%20with%20additional%20Japanese%20language%20training" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20250128_deepseek-ca%2f&amp;title=Using%20LLM%20based%20on%20DeepSeek-R1-Distill-Qwen-14B%2f32B%20with%20additional%20Japanese%20language%20training" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20250128_deepseek-ca%2f&amp;description=Using%20LLM%20based%20on%20DeepSeek-R1-Distill-Qwen-14B%2f32B%20with%20additional%20Japanese%20language%20training" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://akenji3.github.io/en/post/20250127_openfoam_env/" data-toggle="tooltip" data-placement="top" title="Improved OpenFOAM environment">&larr; Previous Post</a>
            </li>
          
          
            <li class="next">
              <a href="https://akenji3.github.io/en/post/20250321_2d_flowovercylinder/" data-toggle="tooltip" data-placement="top" title="Simulation of 2D flow over cylinder">Next Post &rarr;</a>
            </li>
          
        </ul>
      


      

    </div>
  </div>
</div>

      <footer>
  <div class="container">
    
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
          
          
          
        </ul>
        <p class="credits copyright text-muted">
          

          &nbsp;&bull;&nbsp;&copy;
          
            2025
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://akenji3.github.io/en/">akenji&#39;s lab</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.147.1</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js" integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

<script src="https://akenji3.github.io/js/main.js"></script>
<script src="https://akenji3.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://akenji3.github.io/js/load-photoswipe.js"></script>










    
  </body>
</html>

