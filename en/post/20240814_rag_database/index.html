<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Create and evaluate databases for RAG - akenji&#39;s lab</title>
  <meta name="description" content="Introduction.
Create databases that can be used by RAG from the text data for RAG created yesterday, prepare a few specific strings, and search and evaluate them.">
  <meta name="author" content="Kenji Arai"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "akenji\u0027s lab",
    
    "url": "https:\/\/akenji3.github.io"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/akenji3.github.io"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/akenji3.github.io",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/akenji3.github.io\/en\/post\/20240814_rag_database\/",
          "name": "Create and evaluate databases for r a g"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Kenji Arai"
  },
  "headline": "Create and evaluate databases for RAG",
  "description" : "Introduction. Create databases that can be used by RAG from the text data for RAG created yesterday, prepare a few specific strings, and search and evaluate them.\n",
  "inLanguage" : "en",
  "wordCount":  5808 ,
  "datePublished" : "2024-08-14T00:00:00",
  "dateModified" : "2024-08-14T00:00:00",
  "image" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
  "keywords" : [ "" ],
  "mainEntityOfPage" : "https:\/\/akenji3.github.io\/en\/post\/20240814_rag_database\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/akenji3.github.io",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>

<meta property="og:title" content="Create and evaluate databases for RAG" />
<meta property="og:description" content="Introduction.
Create databases that can be used by RAG from the text data for RAG created yesterday, prepare a few specific strings, and search and evaluate them.">
<meta property="og:image" content="https://akenji3.github.io/img/avatar-icon.png" />
<meta property="og:url" content="https://akenji3.github.io/en/post/20240814_rag_database/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="akenji&#39;s lab" />

  <meta name="twitter:title" content="Create and evaluate databases for RAG" />
  <meta name="twitter:description" content="Introduction.
Create databases that can be used by RAG from the text data for RAG created yesterday, prepare a few specific strings, and search and evaluate them.">
  <meta name="twitter:image" content="https://akenji3.github.io/img/avatar-icon.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@akenji3" />
  <meta name="twitter:creator" content="@akenji3" />
  <link href='https://akenji3.github.io/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.74.3" />
  <link rel="alternate" href="https://akenji3.github.io/en/index.xml" type="application/rss+xml" title="akenji&#39;s lab"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link rel="stylesheet" href="https://akenji3.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://akenji3.github.io/css/highlight.min.css" /><link rel="stylesheet" href="https://akenji3.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">



<meta name="google-site-verification" content="j8CZGVXeJvndIocFmzuHgNW2yAd7f30cM9gMYPGqDpE" />


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-TGXWYJXF48', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://akenji3.github.io/en/">akenji&#39;s lab</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/en">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/en/page/about/">About</a>
            </li>
          
        
          
            <li>
              <a title="Categories" href="/en/categories">Categories</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/en/tags">Tags</a>
            </li>
          
        

        
          
            <li>
              
                
              
                
                  <a href="/ja" lang="ja">ja</a>
                
              
            </li>
          
        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="akenji&#39;s lab" href="https://akenji3.github.io/en/">
            <img class="avatar-img" src="https://akenji3.github.io/img/avatar-icon.png" alt="akenji&#39;s lab" />
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Create and evaluate databases for RAG</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on August 14, 2024
  
  
  
  
    
      &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Kenji Arai
    
  
  &nbsp;&bull;&nbsp;Other languages: <a href="https://akenji3.github.io/post/20240814_rag_database/" lang="ja">ja</a>
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <h2 id="introduction">Introduction.</h2>
<p>Create databases that can be used by RAG from the text data for RAG created yesterday, prepare a few specific strings, and search and evaluate them.</p>
<h2 id="sources">Sources</h2>
<ol>
<li><a href="https://www.ohmsha.co.jp/book/9784274231957/">LLM Fine Tuning and RAG</a> The book where I learned about RAG systematically. The parts of creating vector databases and keyword bases (using BM25) are what I learned from this book.</li>
</ol>
<h2 id="environment-used">Environment used</h2>
<p>To build the vector store, we used the GPU version of the FAISS package. Also, when creating the Japanese keyword base, a package named janome was used for Japanese morphological analysis to extract keywords. To clarify the container environment used in this project, the Dockerfile is shown below.</p>
<div class="highlight"><pre class="chroma"><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># Docker image with JupyterLab available</span><span class="err">
</span><span class="err"></span><span class="c"># Installed packages required for the NoteBooks I have created so far.</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">FROM</span><span class="s"> nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Set bash as the default shell</span><span class="err">
</span><span class="err"></span><span class="k">ENV</span> <span class="nv">SHELL</span><span class="o">=</span>/bin/bash<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Build with some basic utilities</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> apt update <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> apt install -y <span class="se">\
</span><span class="se"></span>        wget <span class="se">\
</span><span class="se"></span>        bzip2 <span class="se">\
</span><span class="se"></span>        git <span class="se">\
</span><span class="se"></span>        git-lfs <span class="se">\
</span><span class="se"></span>        curl <span class="se">\
</span><span class="se"></span>        unzip <span class="se">\
</span><span class="se"></span>        file <span class="se">\
</span><span class="se"></span>        xz-utils <span class="se">\
</span><span class="se"></span>        sudo <span class="se">\
</span><span class="se"></span>        python3 <span class="se">\
</span><span class="se"></span>        python3-pip <span class="o">&amp;&amp;</span> <span class="se">\
</span><span class="se"></span>        apt-get autoremove -y <span class="o">&amp;&amp;</span> <span class="se">\
</span><span class="se"></span>        apt-get clean <span class="o">&amp;&amp;</span> <span class="se">\
</span><span class="se"></span>        rm -rf /usr/local/src/*<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># alias python=&#39;python3&#39;</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> ln -s /usr/bin/python3 /usr/bin/python<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> pip install --upgrade pip setuptools <span class="se">\
</span><span class="se"></span> 	<span class="o">&amp;&amp;</span> pip install <span class="nv">torch</span><span class="o">==</span>2.2.2 <span class="nv">torchvision</span><span class="o">==</span>0.17.2 <span class="nv">torchaudio</span><span class="o">==</span>2.2.2 <span class="se">\
</span><span class="se"></span>	--index-url https://download.pytorch.org/whl/cu121 <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install torch torchvision torchaudio <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install jupyterlab matplotlib pandas scikit-learn ipywidgets <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install transformers accelerate sentencepiece einops <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install langchain bitsandbytes protobuf <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install auto-gptq optimum <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install pypdf tiktoken sentence_transformers faiss-gpu trafilatura <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install langchain-community langchain_openai wikipedia <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install langchain-huggingface unstructured html2text rank-bm25 janome <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install langchain-chroma sudachipy sudachidict_full <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install mysql-connector-python<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Install llama-cpp-python[server] with cuBLAS on</span><span class="err">
</span><span class="err"></span><span class="c">#RUN CMAKE_ARGS=&#34;-DLLAMA_CUBLAS=on&#34; FORCE_CMAKE=1 \</span><span class="err">
</span><span class="err"></span><span class="c">#        pip install llama-cpp-python[server]==0.2.75 --force-reinstall --no-cache-dir</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> <span class="nv">CMAKE_ARGS</span><span class="o">=</span><span class="s2">&#34;-DGGML_CUDA=on&#34;</span> <span class="nv">FORCE_CMAKE</span><span class="o">=</span><span class="m">1</span> <span class="se">\
</span><span class="se"></span>        pip install llama-cpp-python<span class="o">[</span>server<span class="o">]</span> --force-reinstall --no-cache-dir<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> pip install -U <span class="nv">numpy</span><span class="o">==</span>1.26.4 <span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Create a working directory</span><span class="err">
</span><span class="err"></span><span class="k">WORKDIR</span><span class="s"> /workdir</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Port number in container side</span><span class="err">
</span><span class="err"></span><span class="k">EXPOSE</span><span class="s"> 8888</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">ENTRYPOINT</span> <span class="p">[</span><span class="s2">&#34;jupyter-lab&#34;</span><span class="p">,</span> <span class="s2">&#34;--ip=0.0.0.0&#34;</span><span class="p">,</span> <span class="s2">&#34;--port=8888&#34;</span><span class="p">,</span> <span class="s2">&#34;--no-browser&#34;</span><span class="p">,</span> <span class="s2">&#34;--allow-root&#34;</span><span class="p">,</span> <span class="s2">&#34;--NotebookApp.token=&#39;&#39;&#34;</span><span class="p">]</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">CMD</span> <span class="p">[</span><span class="s2">&#34;--notebook-dir=/workdir&#34;</span><span class="p">]</span><span class="err">
</span></code></pre></div><p>As for Japanese morphological analysis, sudachi was also tried, so its related packages are also included. Also, mysql-related packages are included because, as I mentioned in a recent post, I built a MySQL (MariaDB) server and put them in to connect to it. Both are not in use now.</p>
<h2 id="create-database">Create database</h2>
<p>The vector database (wiki_vs.db) and keyword base (wiki_kw.pkl) are created with the following codes respectively.</p>
<p>Also, the text file named &ldquo;textdb&rdquo; created yesterday is stored in the same folder as &ldquo;wiki_text&rdquo;.</p>
<h4 id="vector-database">Vector database</h4>
<h4 id="heading"></h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Vector databaseを作成する。</span>

<span class="kn">import</span> <span class="nn">time</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#　Wikipediaから天文関係の記事のみを抽出したテキストデータは、WIKI_TEXTとして事前に準備。</span>
<span class="c1"># VectorStoreするため、テキストコーパスをチャンクに分割。</span>
<span class="n">WIKI_TEXT</span> <span class="o">=</span> <span class="s2">&#34;wiki_text&#34;</span>

<span class="c1"># チャンク文字数、オーバラップ文字数を定義</span>
<span class="n">CHUNK_SIZE</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">CHUNK_OVERLAP</span> <span class="o">=</span> <span class="mi">30</span>

<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">WIKI_TEXT</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
    <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">CHUNK_SIZE</span><span class="p">,</span>  <span class="c1"># チャンクの文字数</span>
    <span class="n">chunk_overlap</span> <span class="o">=</span> <span class="n">CHUNK_OVERLAP</span><span class="p">,</span>  <span class="c1"># チャンクオーバーラップの文字数</span>
<span class="p">)</span>

<span class="n">texts</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">WIKI_TEXT</span> <span class="o">=</span> <span class="s2">&#34;wiki_text&#34;</span>
<span class="n">WIKI_DB</span> <span class="o">=</span> <span class="s2">&#34;wiki_vs.db&#34;</span>

<span class="c1">## データベースを構築</span>

<span class="kn">from</span> <span class="nn">langchain_huggingface</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&#34;intfloat/multilingual-e5-large&#34;</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&#34;/workdir/models/{model_name}&#34;</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">HuggingFaceEmbeddings</span><span class="p">(</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="n">model_path</span><span class="p">,</span>
    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">},</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>

<span class="c1"># ベクトルデータベースを構築し、WIKI_DBとして保存する</span>

<span class="n">db</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_texts</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">db</span><span class="o">.</span><span class="n">save_local</span><span class="p">(</span><span class="n">WIKI_DB</span><span class="p">)</span>
</code></pre></div><p>The embedding model is downloaded from HuggingFace in advance and stored in the model_path.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">processing_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&#34;processing_time(sec): &#34;</span><span class="p">,</span> <span class="n">processing_time</span><span class="p">)</span>
</code></pre></div><p>The execution result (processing time) is as follows. It took about 12 minutes in my environment.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">processing_time</span><span class="p">(</span><span class="n">sec</span><span class="p">):</span>  <span class="mf">704.8360137939453</span>
</code></pre></div><h4 id="keyword-based">keyword-based</h4>
<h4 id="heading-1"></h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># キーワード検索用のデータベースを作成</span>
<span class="c1">#</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># my_preprocess_funcを定義</span>

<span class="kn">from</span> <span class="nn">janome.tokenizer</span> <span class="kn">import</span> <span class="n">Tokenizer</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">my_preprocess_func</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">t</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">part_of_speech</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">pos</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&#34;名詞&#34;</span><span class="p">,</span> <span class="s2">&#34;動詞&#34;</span><span class="p">,</span> <span class="s2">&#34;形容詞&#34;</span><span class="p">]):</span>
            <span class="n">keywords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">surface</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">keywords</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#　Wikipediaから天文関係の記事のみを抽出したテキストデータは、WIKI_TEXTとして事前に準備。</span>
<span class="c1"># キーワードベースのデータベースを作成するため、テキストコーパスをチャンクに分割。</span>
<span class="n">WIKI_TEXT</span> <span class="o">=</span> <span class="s2">&#34;wiki_text&#34;</span>

<span class="c1"># チャンク文字数、オーバラップ文字数を定義</span>
<span class="n">CHUNK_SIZE</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">CHUNK_OVERLAP</span> <span class="o">=</span> <span class="mi">30</span>

<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">WIKI_TEXT</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
    <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">CHUNK_SIZE</span><span class="p">,</span>  <span class="c1"># チャンクの文字数</span>
    <span class="n">chunk_overlap</span> <span class="o">=</span> <span class="n">CHUNK_OVERLAP</span><span class="p">,</span>  <span class="c1"># チャンクオーバーラップの文字数</span>
<span class="p">)</span>

<span class="n">texts</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">langchain_community.retrievers</span> <span class="kn">import</span> <span class="n">BM25Retriever</span>

<span class="n">WIKI_DB</span> <span class="o">=</span> <span class="s2">&#34;wiki_kw.pkl&#34;</span>

<span class="n">db</span> <span class="o">=</span> <span class="n">BM25Retriever</span><span class="o">.</span><span class="n">from_texts</span><span class="p">(</span>
    <span class="n">texts</span><span class="p">,</span>
    <span class="n">preprocess_func</span><span class="o">=</span><span class="n">my_preprocess_func</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">pickle</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">WIKI_DB</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">processing_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&#34;processing_time(sec): &#34;</span><span class="p">,</span> <span class="n">processing_time</span><span class="p">)</span>
</code></pre></div><p>The results (processing time) are as follows.　It took about 13 minutes in my environment.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">processing_time</span><span class="p">(</span><span class="n">sec</span><span class="p">):</span>  <span class="mf">753.1111702919006</span>
</code></pre></div><h2 id="evaluate-try-and-search-the-database-you-created">Evaluate (try and search) the database you created</h2>
<h4 id="vector-database-1">Vector database</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># ベクトルデータベース検索結果を評価する</span>
<span class="c1"># </span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">WIKI_DB</span> <span class="o">=</span> <span class="s2">&#34;wiki_vs.db&#34;</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">langchain_huggingface</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&#34;intfloat/multilingual-e5-large&#34;</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&#34;/workdir/models/{model_name}&#34;</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">HuggingFaceEmbeddings</span><span class="p">(</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="n">model_path</span><span class="p">,</span>
    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">},</span>
<span class="p">)</span>

<span class="c1"># 事前に構築したベクトルデータベースを読み込む</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">WIKI_DB</span><span class="p">):</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">load_local</span><span class="p">(</span><span class="n">WIKI_DB</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">allow_dangerous_deserialization</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;You need to make vector database&#34;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># ベクトル検索で4文書を得る</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;r過程について教えてください&#34;</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;1st: {docs[0].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;2nd: {docs[1].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;3rd: {docs[2].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;4th: {docs[3].page_content}&#34;</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># ベクトル検索で4文書を得る</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;ナンシー・グレース・ローマン宇宙望遠鏡について教えてください&#34;</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;1st: {docs[0].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;2nd: {docs[1].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;3rd: {docs[2].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;4th: {docs[3].page_content}&#34;</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># ベクトル検索で4文書を得る</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;B2FH論文について教えてください&#34;</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;1st: {docs[0].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;2nd: {docs[1].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;3rd: {docs[2].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;4th: {docs[3].page_content}&#34;</span><span class="p">)</span>
</code></pre></div><h4 id="keyword-based-1">keyword-based</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># キーワード検索結果を評価する</span>
<span class="c1"># </span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">janome.tokenizer</span> <span class="kn">import</span> <span class="n">Tokenizer</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">my_preprocess_func</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">t</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">part_of_speech</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">pos</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&#34;名詞&#34;</span><span class="p">,</span> <span class="s2">&#34;動詞&#34;</span><span class="p">,</span> <span class="s2">&#34;形容詞&#34;</span><span class="p">]):</span>
            <span class="n">keywords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">surface</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">keywords</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">WIKI_DB</span> <span class="o">=</span> <span class="s2">&#34;wiki_kw.pkl&#34;</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">langchain_community.retrievers</span> <span class="kn">import</span> <span class="n">BM25Retriever</span>

<span class="c1"># 事前に構築したキーワードのデータベースを読み込む</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">WIKI_DB</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">WIKI_DB</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">retriever</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;You need to make keyword database&#34;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># キーワード検索で4文書を得る</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;r過程について教えてください&#34;</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;1st: {docs[0].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;2nd: {docs[1].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;3rd: {docs[2].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;4th: {docs[3].page_content}&#34;</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># キーワード検索で4文書を得る</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;ナンシー・グレース・ローマン宇宙望遠鏡について教えてください&#34;</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;1st: {docs[0].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;2nd: {docs[1].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;3rd: {docs[2].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;4th: {docs[3].page_content}&#34;</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># キーワード検索で4文書を得る</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;B2FH論文について教えてください&#34;</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;1st: {docs[0].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;2nd: {docs[1].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;3rd: {docs[2].page_content}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;4th: {docs[3].page_content}&#34;</span><span class="p">)</span>
</code></pre></div><h3 id="comparison-of-results">Comparison of results</h3>
<p>The output results are copied and pasted directly into the table below.</p>
<p>Search results, so the original text (in Japanese) remains the same.</p>
<table>
<thead>
<tr>
<th>ベクトルデータベース</th>
<th>キーワードベース</th>
</tr>
</thead>
<tbody>
<tr>
<td>1st: b（.02）とTOI-1670 <!-- raw HTML omitted -->2nd: Rp過程rp過程(rp かてい,高速陽子捕獲過程 ) は、種核種に連続的に陽子が捕獲され重元素を作り出す過程である.これは元素合成過程であり、 s過程やr過程とともに宇宙に存在する重元素の生成にかかわっている。しかしながら、他の元素合成過程とは、他の過程が中性子に富む側の安定性が問題になるのに対し、陽子に富む側の安定性が問題になる点がかなり違っている。rp過程の終了点(生成することの出来る最重元素)は良くわかっていないが最近の中性子星に関する研究により、テルルより先へ反応が進まないことがわかっている。 <!-- raw HTML omitted -->3rd: 植物の構成を大きく置き換えるなどの動植物の変化を引き起こした&lt;ref <!-- raw HTML omitted -->4th: ()ではエネルギー曲線が不連続になる</td>
<td>1st: II型）でr過程が起こると広く信じられてきた。しかしながら、r過程核種の存在比からすると、超新星爆発のうち、ほんの少しの事例でr過程核種を星間物質に放出するか、それぞれの超新星爆発で生成されたr過程核種のうち、ほんの少しの部分を放出するということを要請する。またコンピューターシミュレーションでも超新星爆発によってr過程が生じなかったため、超新星爆発がr過程の発生する現場であることに疑問が持たれていた。別の候補として中性子星同士の衝突によってr過程が起こりうる可能性があることが知られていたが、2014年、国立天文台・東京大学の研究チームによって中性子星の合体によるr過程が矛盾なく説明できるとの <!-- raw HTML omitted -->2nd: 合成できる環境が考えられる。恒星内元素合成の間に起こるs過程は最大で原子量209のビスマスまでの元素を合成することが可能である。s過程は主に低質量の反応段階の進展の遅い恒星に起こる。r過程.2017年8月、中性子星同士の衝突現象が観測され、その現象を分析した結果、中性子星の衝突によるr過程元素の合成が確認された。この分析結果により、r過程が中性子星同士の融合によって発生することが証明されている。上記の現象が分析されるまでは、恒星核が重力崩壊する超新星爆発（スペクトル型 <!-- raw HTML omitted -->3rd: (Slow)&ldquo;の中性子捕獲過程によって、鉄以降の重元素のおよそ半分が合成される。残りの半分はr過程と呼ばれるより&quot;速く <!-- raw HTML omitted -->4th: あると誤解されることがある。ノーベル物理学賞の選考委員会は受賞理由を「宇宙における化学元素の生成にとって重要な原子核反応に関する理論的および実験的研究」としている。ファウラーがノーベル賞を受賞した一方で、ホイルは生涯受賞できなかった。ホイルがノーベル物理学賞を受賞できなかった理由について、「ファウラーのBFHへの貢献には、s過程とr過程の原子核物理学も含まれるが、ホイルもまたs過程とr過程に関する理論的研究でファウラー同様の評価を受けるに値する。ビッグバンに関するホイルの否定的な見解がノーベル賞受賞の妨げになった。」と主張するものもいる。ホイルが受賞できなかった理由について、ジェフリー・バービ</td>
</tr>
<tr>
<td>1st: ナンシー・グレース・ローマン宇宙望遠鏡、略称 ローマン宇宙望遠鏡 (, Roman Space Telescope) は、2020年代半ばの打ち上げを目指し、日本を含む国際協力で進められているアメリカ航空宇宙局 (NASA) の広視野赤外線宇宙望遠鏡計画。&ldquo;Wide Field Infrared Survey Telescope&rdquo; （広視野近赤外線サーベイ宇宙望遠鏡）の頭文字を取って WFIRST という名称で計画が進められていたが、2020年5月20日、NASAは正式名称を Nancy Grace Roman Space Telescope <!-- raw HTML omitted -->2nd: (JWST) が2021年12月25日に打ち上げられた。六角形の鏡を18枚組み合わせた主鏡の口径は約6.5mであり、ハッブル宇宙望遠鏡よりも大幅な高性能化が図られている。ただし観測波長域は近赤外線・赤外線のみであり、近紫外線・可視光の観測能力は持たない。地球と太陽のラグランジュ点 (L2) に位置することで、地球近傍の塵の影響を避け、より高精度の観測を可能としている。元は2011年の打ち上げ予定であったが、度々延期されたものである。ナンシー・グレース・ローマン宇宙望遠鏡.2012年6月4日、アメリカ国家偵察局 (NRO) <!-- raw HTML omitted -->3rd: Grace Roman Space Telescope と定めたと発表した。ナンシー・グレース・ローマンは、1960年代以降NASAの宇宙望遠鏡計画実現に重要な役割を果たし、特にハッブル宇宙望遠鏡の計画実現のためNASA内部や議会へ積極的な働きかけをしたことから「ハッブルの母 (Mother of Hubble) <!-- raw HTML omitted -->4th: Hubble&rdquo;)」とも呼ばれた。また、ローマンはそのキャリアを通じて、積極的な講演者や教育者、科学分野における女性の擁護者でもあった。2020年5月20日、NASAのジム・ブライデンスタイン長官は、彼女の天文学への絶えることのない貢献を称え、計画中の赤外線宇宙望遠鏡WFIRSTをナンシー・グレース・ローマン宇宙望遠鏡と命名することを発表した。若年期.ナンシー・グレース・ローマンは、テネシー州ナッシュビルで、音楽教師のジョージア・フランシス・スミス・ローマンと物理学者・数学者のアーウィン・ローマンの間に生まれた。生後間もなく、父親が石油会社の地球物理学者として就職したため、生後3ヶ月で一家はオ</td>
<td>1st: Hubble&rdquo;)」とも呼ばれた。また、ローマンはそのキャリアを通じて、積極的な講演者や教育者、科学分野における女性の擁護者でもあった。2020年5月20日、NASAのジム・ブライデンスタイン長官は、彼女の天文学への絶えることのない貢献を称え、計画中の赤外線宇宙望遠鏡WFIRSTをナンシー・グレース・ローマン宇宙望遠鏡と命名することを発表した。若年期.ナンシー・グレース・ローマンは、テネシー州ナッシュビルで、音楽教師のジョージア・フランシス・スミス・ローマンと物理学者・数学者のアーウィン・ローマンの間に生まれた。生後間もなく、父親が石油会社の地球物理学者として就職したため、生後3ヶ月で一家はオ <!-- raw HTML omitted -->2nd: Grace Roman Space Telescope と定めたと発表した。ナンシー・グレース・ローマンは、1960年代以降NASAの宇宙望遠鏡計画実現に重要な役割を果たし、特にハッブル宇宙望遠鏡の計画実現のためNASA内部や議会へ積極的な働きかけをしたことから「ハッブルの母 (Mother of Hubble) <!-- raw HTML omitted -->3rd: ナンシー・グレース・ローマン宇宙望遠鏡、略称 ローマン宇宙望遠鏡 (, Roman Space Telescope) は、2020年代半ばの打ち上げを目指し、日本を含む国際協力で進められているアメリカ航空宇宙局 (NASA) の広視野赤外線宇宙望遠鏡計画。&ldquo;Wide Field Infrared Survey Telescope&rdquo; （広視野近赤外線サーベイ宇宙望遠鏡）の頭文字を取って WFIRST という名称で計画が進められていたが、2020年5月20日、NASAは正式名称を Nancy Grace Roman Space Telescope <!-- raw HTML omitted -->4th: ナンシー・ローマンナンシー・グレース・ローマン（Nancy Grace Roman、1925年5月16日 - 2018年12月25日）は、1950年代に恒星の分類と運動の研究に多大な貢献を果たしたアメリカの天文学者。アメリカ航空宇宙局 (NASA) において女性として初めて幹部職に就き、1960年代から1970年代にかけてNASAの初代主任天文学者として宇宙天文学プログラムをスタートさせた。ハッブル宇宙望遠鏡計画では、天文学コミュニティや議会を動かすなど基礎を築く役割を果たしたことから「ハッブルの母 (&ldquo;Mother of</td>
</tr>
<tr>
<td>1st: B2FH論文BFH論文 (BFH paper) は、元素の起源に関する記念碑的な論文である。論文の題名は &ldquo;Synthesis of the Elements in Stars&rdquo; だが、著者であるマーガレット・バービッジ、ジェフリー・バービッジ、ウィリアム・ファウラー、フレッド・ホイルの4名の頭文字を取って「B2FH」として知られている。1955年から1956年にかけてケンブリッジ大学とカリフォルニア工科大学で執筆され、1957年にアメリカ物理学会の査読付き学術誌&quot;Reviews of Modern <!-- raw HTML omitted -->2nd: b（.02）とTOI-1670 <!-- raw HTML omitted -->3rd: formula_16 である。この論文で、トフーフトは formula_16 <!-- raw HTML omitted -->4th: using the background-field method」や、と共同執筆した「The finiteness requirement for six-dimensional Euclidean-Einstein</td>
<td>1st: B2FH論文BFH論文 (BFH paper) は、元素の起源に関する記念碑的な論文である。論文の題名は &ldquo;Synthesis of the Elements in Stars&rdquo; だが、著者であるマーガレット・バービッジ、ジェフリー・バービッジ、ウィリアム・ファウラー、フレッド・ホイルの4名の頭文字を取って「B2FH」として知られている。1955年から1956年にかけてケンブリッジ大学とカリフォルニア工科大学で執筆され、1957年にアメリカ物理学会の査読付き学術誌&quot;Reviews of Modern <!-- raw HTML omitted -->2nd: 年にはワシントン大学の客員教授を務めた。業績.1957年にマーガレット・バービッジ、ジェフリー・バービッジ、フレッド・ホイルと共著の論文（4人の名前からB2FH論文と呼ばれる）は、恒星のなかでの元素の起源に関するその分野での重要な論文である。ファウラーは、炭素を合成するトリプルアルファ反応が働くために必要なエネルギー準位を、炭素原子核が持つことを実験で証明した。 <!-- raw HTML omitted -->3rd: ということを1952年に提唱し、ホイルにその節を示唆されたウィリアム・ファウラーは、実際にそのような準位が存在することを示し、B2FH論文と呼ばれる世界的な論文を1957年に発表した。今日ではこのような考え方を人間原理と呼び、その例として挙げられることもあるが、2010年に出された論文では、少なくともホイルは炭素を基盤とした生命体である人間の存在を仮定してこの説を唱えたわけではないとするものが出された。 <!-- raw HTML omitted -->4th: ッグ放射線研究所に赴いて、所長のウィリアム・ファウラーの協力で、泡箱を用いて原子核の衝突実験（3個のヘリウムでできる炭素の原子核の性質を調べる実験）を成功させた。これにより炭素は星のなかで無尽蔵に作られる性質があることが判った。その後も彼ら2人を含めて数名が元素の歴史に迫り、B2FH論文に結実させた。だが、こうした論文は定常モデルに有利に働いたというよりむしろ、ハッブルの観測によって導かれた星の進化に関するアイディア群がより完成度を高めた、と一般には見なされた。《ビッグバン</td>
</tr>
</tbody>
</table>
<h2 id="summary">Summary</h2>
<p>In the above search example (using the keywords - r process, Nancy Grace Roman Space Telescope, B2FH paper - for which there is always an explanation in the original text data), the keyword search seems to hit better.
In the example of the r-process in the vector database, it seems to miss all but the 2nd, and in the example of the B2FH paper, it seems to miss all but the 1st.</p>
<p>I feel that this is where the difficulty lies with vector database.</p>

        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240814_rag_database%2f&amp;text=Create%20and%20evaluate%20databases%20for%20RAG&amp;via=akenji3" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240814_rag_database%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240814_rag_database%2f&amp;title=Create%20and%20evaluate%20databases%20for%20RAG" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240814_rag_database%2f&amp;title=Create%20and%20evaluate%20databases%20for%20RAG" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240814_rag_database%2f&amp;title=Create%20and%20evaluate%20databases%20for%20RAG" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20240814_rag_database%2f&amp;description=Create%20and%20evaluate%20databases%20for%20RAG" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://akenji3.github.io/en/post/20240813_wikipedia_dump/" data-toggle="tooltip" data-placement="top" title="Creating text data for RAG from Wikipedia dump data">&larr; Previous Post</a>
            </li>
          
          
        </ul>
      


      

    </div>
  </div>
</div>

      
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:akenji.1118@gmail.com" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://www.facebook.com/arai.kenji3" title="Facebook">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-facebook fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://github.com/akenji3" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/akenji3" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/kenji-arai-0547aa1a4" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            <a href="" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fas fa-circle fa-stack-2x"></i>
                <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              Kenji Arai
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2024
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://akenji3.github.io/en/">akenji&#39;s lab</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.74.3</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="https://akenji3.github.io/js/main.js"></script>
<script src="https://akenji3.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script> renderMathInElement(document.body); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://akenji3.github.io/js/load-photoswipe.js"></script>








<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']]
  }
});
</script>


    
  </body>
</html>

