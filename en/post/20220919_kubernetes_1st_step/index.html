

<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

 


      <title>Building a GPU Cluster with Kubernetes - the First Steps - </title>

  <meta name="description" content="Introduction
About a month ago, I wrote an article about building a GPU cluster using kubernetes in this article. At that time, the GPU pod was in Pending state and did not work. After that, I managed to get it to work thanks to the advice of a certain person, so I&rsquo;ll summarize it here.
In my environment, there is a problem that the GPU pod does not start up until a certain node is started, and furthermore, I have not been able to specify GPUs in a node, specify nodes, and so on, which is what I assumed, so I decided to call it &ldquo;the first step&rdquo;."><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "akenji\u0027s lab",
    
    "url": "https:\/\/akenji3.github.io\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/akenji3.github.io\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/akenji3.github.io\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/akenji3.github.io\/en\/post\/20220919_kubernetes_1st_step\/",
          "name": "Building a gpu cluster with kubernetes the first steps"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : ""
  },
  "headline": "Building a GPU Cluster with Kubernetes - the First Steps",
  "description" : "Introduction About a month ago, I wrote an article about building a GPU cluster using kubernetes in this article. At that time, the GPU pod was in Pending state and did not work. After that, I managed to get it to work thanks to the advice of a certain person, so I\u0026rsquo;ll summarize it here.\nIn my environment, there is a problem that the GPU pod does not start up until a certain node is started, and furthermore, I have not been able to specify GPUs in a node, specify nodes, and so on, which is what I assumed, so I decided to call it \u0026ldquo;the first step\u0026rdquo;.\n",
  "inLanguage" : "en",
  "wordCount":  1421 ,
  "datePublished" : "2022-09-19T00:00:00\u002b00:00",
  "dateModified" : "2022-09-19T00:00:00\u002b00:00",
  "image" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
  "keywords" : [ "" ],
  "mainEntityOfPage" : "https:\/\/akenji3.github.io\/en\/post\/20220919_kubernetes_1st_step\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/akenji3.github.io\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>


<meta property="og:title" content="Building a GPU Cluster with Kubernetes - the First Steps" />
<meta property="og:description" content="Introduction
About a month ago, I wrote an article about building a GPU cluster using kubernetes in this article. At that time, the GPU pod was in Pending state and did not work. After that, I managed to get it to work thanks to the advice of a certain person, so I&rsquo;ll summarize it here.
In my environment, there is a problem that the GPU pod does not start up until a certain node is started, and furthermore, I have not been able to specify GPUs in a node, specify nodes, and so on, which is what I assumed, so I decided to call it &ldquo;the first step&rdquo;.">
<meta property="og:image" content="https://akenji3.github.io/img/avatar-icon.png" />
<meta property="og:url" content="https://akenji3.github.io/en/post/20220919_kubernetes_1st_step/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="akenji&#39;s lab" />

  <meta name="twitter:title" content="Building a GPU Cluster with Kubernetes - the First Steps" />
  <meta name="twitter:description" content="Introduction
About a month ago, I wrote an article about building a GPU cluster using kubernetes in this article. At that time, the GPU pod was in Pending state and did not work. After that, I managed …">
  <meta name="twitter:image" content="https://akenji3.github.io/img/avatar-icon.png" />
  <meta name="twitter:card" content="summary_large_image" />
  <link href='https://akenji3.github.io/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.147.1">
  <link rel="alternate" href="https://akenji3.github.io/en/index.xml" type="application/rss+xml" title="akenji&#39;s lab"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css" integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.6.0/css/all.css" integrity="sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"><link rel="stylesheet" href="https://akenji3.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://akenji3.github.io/css/highlight.min.css" /><link rel="stylesheet" href="https://akenji3.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">

      <script async src="https://www.googletagmanager.com/gtag/js?id=G-TGXWYJXF48"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TGXWYJXF48');
        }
      </script>
  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://akenji3.github.io/en/">akenji&#39;s lab</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/en/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/en/page/about/">About</a>
            </li>
          
        
          
            <li>
              <a title="Categories" href="/en/categories">Categories</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/en/tags">Tags</a>
            </li>
          
        

        
          
            <li>
              
                
                  <a href="https://akenji3.github.io/post/20220919_kubernetes_1st_step/">ja</a>
                
              
            </li>
          
        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="akenji&#39;s lab" href="https://akenji3.github.io/en/">
            <img class="avatar-img" src="https://akenji3.github.io/img/avatar-icon.png" alt="akenji&#39;s lab" />
           
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Building a GPU Cluster with Kubernetes - the First Steps</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on September 19, 2022
  
  
  
  
    
      &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;
    
  
  &nbsp;&bull;&nbsp;Other languages: <a href="https://akenji3.github.io/post/20220919_kubernetes_1st_step/" lang="ja">ja</a>
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <h2 id="introduction">Introduction</h2>
<p>About a month ago, I wrote an article about building a GPU cluster using kubernetes in <a href="https://akenji3.github.io/post/20220821_kubernetes/">this article</a>. At that time, the GPU pod was in Pending state and did not work. After that, I managed to get it to work thanks to the advice of a certain person, so I&rsquo;ll summarize it here.</p>
<p>In my environment, there is a problem that the GPU pod does not start up until a certain node is started, and furthermore, I have not been able to specify GPUs in a node, specify nodes, and so on, which is what I assumed, so I decided to call it &ldquo;the first step&rdquo;.</p>
<p>&lt;! &ndash;more&ndash;&gt;</p>
<h2 id="sources">Sources.</h2>
<ol>
<li>[[What you need to know to migrate from NVIDIA Docker (NVIDIA Container Toolkit) to nvidia-container-runtime + containerd](https://blog.inductor.me/entry/ 2020/12/13/042319)] I got the GPU pod in Pending state to work after being told about this page by a person.</li>
</ol>
<p>2.<a href="https://github.com/NVIDIA/k8s-device-plugin">NVIDIA/k8s-device-plugin</a> NVIDIA&rsquo;s device plugin page for kubernetes.</p>
<p>3.<a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/k8s-device-plugin">NVIDIA Kubernetes Device Plugin</a> This page has information on the latest version of the device plugin. I got some information on the latest version of the device plugin from this page.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The following summary is based on my own experience, so there is no guarantee that the following will apply in every environment.</p>
<ul>
<li>&ldquo;CsytemdCgroup = false&rdquo; in /etc/containerd/config.toml in the procedure of <a href="https://docs.nvidia.com/datacenter/cloud-native/kubernetes/install-k8s.html#step-1-install-a-container-engine">Step 1: Install a Container Engine</a> should be left false and not changed to true.</li>
<li><a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.html#install-nvidia-gpu-operator">NVIDIA GPU Operator</a> procedure did not work.</li>
<li>I changed the procedure in <a href="https://docs.nvidia.com/datacenter/cloud-native/kubernetes/install-k8s.html#step-4-setup-nvidia-software">Step 4: Setup NVIDIA Software</a> and installed it. Specifically, I did not use Helm, but used &ldquo;kubectl apply -f&rdquo; to install the device plugin. It worked with the latest version (v0.12.3).</li>
</ul>
<h2 id="installation-operation">Installation operation</h2>
<h4 id="step-1-install-container-engine">Step 1: Install Container Engine</h4>
<h5 id="1-install-necessary-packages">(1) Install necessary packages</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo apt-get update<span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; <span class="o">&amp;&amp;</span> sudo apt-get install -y apt-transport-https <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; ca-certificates curl software-properties-common
</span></span></code></pre></div><p>In my environment, all were the latest versions.</p>
<h5 id="2-set-to-load-overlay-br_netfilter-kernel-modules">(2) set to load overlay, br_netfilter (kernel) modules</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ cat <span class="s">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; overlay
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; br_netfilter
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; EOF</span>
</span></span><span class="line"><span class="cl">$ sudo modprobe overlay <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; <span class="o">&amp;&amp;</span> sudo modprobe br_netfilter
</span></span></code></pre></div><h5 id="3-set-sysctl-parameters-in-conf-file">(3) Set sysctl parameters in conf file</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ cat <span class="s">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; net.ipv4.ip_forward = 1
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; EOF</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ sudo sysctl --system
</span></span></code></pre></div><h5 id="4-configure-docker-repository">(4) Configure Docker repository</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg <span class="p">|</span> sudo apt-key --keyring /etc/apt/trusted.gpg.d/docker.gpg add -
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ sudo add-apt-repository <span class="s2">&#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt; </span><span class="k">$(</span>lsb_release -cs<span class="k">)</span><span class="s2"> \
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt; stable&#34;</span>
</span></span></code></pre></div><h5 id="5-install-containerd">(5) install containerd</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo apt-get update <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; <span class="o">&amp;&amp;</span> sudo apt-get install -y containerd.io
</span></span></code></pre></div><p>In my environment, containerd.io had the latest version (1.6.7-1) already installed.</p>
<h5 id="6-set-default-parameters-for-containerd-by-creating-configtoml">(6) Set default parameters for containerd by (creating) config.toml</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo mkdir -p /etc/containerd <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; <span class="o">&amp;&amp;</span> sudo containerd config default <span class="p">|</span> sudo tee /etc/containerd/config.toml
</span></span></code></pre></div><p>Since containerd.io was already installed, the /etc/containerd directory and config.toml already existed. config.toml was renamed and saved.</p>
<h5 id="7-change-configtoml-so-that-containerd-uses-systemd-cgroup-driver">~~~(7) Change config.toml so that (containerd) uses systemd cgroup driver~~~.</h5>
<p>As mentioned in the conclusion, &ldquo;SystemdCgroup = false&rdquo; should be left as it is.  No changes are made to /etc/containerd/config.toml here.</p>
<h5 id="8-restart-containerd-daemon">(8) Restart containerd daemon</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo systemctl restart containerd
</span></span></code></pre></div><h4 id="step-2-install-kubernetes-components">Step 2: Install Kubernetes components</h4>
<h5 id="1-install-some-dependencies">(1) Install some dependencies</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">$ sudo apt-get update <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; <span class="o">&amp;&amp;</span> sudo apt-get install -y apt-transport-https curl
</span></span></code></pre></div><p>The latest version was installed in my environment.</p>
<h5 id="2-add-repository-key">(2) Add repository key.</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg <span class="p">|</span> sudo apt-key add -
</span></span></code></pre></div><h5 id="3-add-repository">(3) Add repository</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ cat <span class="s">&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; deb https://apt.kubernetes.io/ kubernetes-xenial main
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; EOF</span>
</span></span></code></pre></div><h5 id="4-install-kubelet">(4) Install kubelet</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo apt-get update <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; <span class="o">&amp;&amp;</span> sudo apt-get install -y -q kubelet kubectl kubeadm
</span></span></code></pre></div><h5 id="5-note-1-configure-cgroup-driver-for-kuberlet">(5) Note 1: Configure cgroup driver for Kuberlet</h5>
<p>In the NVIDIA documentation, section 1 of Note.</p>
<p>At this point, 10-kubeadm.conf already exists under /etc/systemd/system/kuberlet.service.d.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo cat <span class="s">&lt;&lt; EOF | sudo tee /etc/systemd/system/kubelet.service.d/0-containerd.conf
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; [Service]
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; Environment=&#34;KUBELET_EXTRA_ARGS=--container-runtime=remote --runtime-request-timeout=15m --container-runtime-endpoint=unix:///run/containerd/containerd.sock --cgroup-driver=&#39;systemd&#39;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; EOF</span>
</span></span></code></pre></div><h5 id="6-note-2-restart-kubelet">(6) Note 2: Restart kubelet</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo systemctl daemon-reload <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; <span class="o">&amp;&amp;</span> sudo systemctl restart kubelet
</span></span></code></pre></div><h5 id="7-disable-swap">(7) Disable swap</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ swapon --show
</span></span><span class="line"><span class="cl">NAME TYPE SIZE USED PRIO
</span></span><span class="line"><span class="cl">/swapfile file 2G 0B -2
</span></span><span class="line"><span class="cl">$ sudo swapoff -a
</span></span><span class="line"><span class="cl">$ swapon --show
</span></span><span class="line"><span class="cl">$
</span></span></code></pre></div><p>The above operation is temporary, and swap is enabled again when the server is restarted.
To disable it permanently, insert # at the beginning of any line in /etc/fstab that contains &ldquo;swap&rdquo; to disable it. (In my environment, the line starts with /swapfile)</p>
<h5 id="8-run-kubeadm-init">(8) Run kubeadm init</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo kubeadm init --pod-network-cidr<span class="o">=</span>192.168.0.0/16
</span></span><span class="line"><span class="cl"><span class="o">[</span>init<span class="o">]</span> Using Kubernetes version: v1.24.3
</span></span><span class="line"><span class="cl">... Omitted.
</span></span><span class="line"><span class="cl">Then you can join any number of worker nodes by running the following on each as root:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubeadm join 192.168.11.3:6443 --token 7ffwr1.xm119vzqvmhqgevl <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>	--discovery-token-ca-cert-hash sha256:5d2f3065e38020b668ba1b766d95aea197182e35143511db7062f247f12c81d3 
</span></span></code></pre></div><p>Make a note of this part &ldquo;kubeadm join &hellip; sha256&hellip;&rdquo;. You can create a cluster as a woker node by executing the following:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo kubeadm join 192.168.11.3:6443 --token 7ffwr1.xm119vzqvmhqgevl <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; --discovery-token-ca-cert-hash sha256:5d2f3065e38020b668ba1b766d95aea197182e35143511db7062f247f12c81d3 
</span></span><span class="line"><span class="cl"><span class="o">[</span>preflight<span class="o">]</span> Running pre-flight checks
</span></span><span class="line"><span class="cl">... Omitted...
</span></span><span class="line"><span class="cl">This node has joined the cluster:
</span></span><span class="line"><span class="cl">* Certificate signing request was sent to apiserver and a response was received.
</span></span><span class="line"><span class="cl">* The Kubelet was informed of the new secure connection details.
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Run <span class="s1">&#39;kubectl get nodes&#39;</span> on the control-plane to see this node join the cluster.
</span></span></code></pre></div><h5 id="9-copy-authentication-files-under-home">(9) Copy authentication files under $HOME</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ mkdir -p <span class="nv">$HOME</span>/.kube <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; <span class="o">&amp;&amp;</span> sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>&gt; <span class="o">&amp;&amp;</span> sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config
</span></span></code></pre></div><h4 id="step-3-configure-the-network">Step 3: Configure the network</h4>
<h5 id="1-configure-network-in-calico">(1) Configure network in Calico</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
</span></span></code></pre></div><h5 id="2-assign-the-worker-role-to-master-as-well">(2) Assign the worker role to master as well</h5>
<p>As the NVIDIA documentation says &ldquo;GPU Pods can be scheduled on the simplest single-node clusters&rdquo;, it is possible to schedule a Pod on the master (control plane) node as well.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ kubectl taint nodes --all node-role.kubernetes.io/master-
</span></span></code></pre></div><p>In my environment, I did not want to schedule a pod on the master node, so I did not run this.</p>
<p>Now, you have one master (control plane) node (kubeadm init operation) and one worker node (kubeadm join operation) each. The state of the node in my environment is as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ kubectl get nodes
</span></span><span class="line"><span class="cl">NAME STATUS ROLES AGE VERSION
</span></span><span class="line"><span class="cl">europe Ready control-plane 2m57s v1.25.0
</span></span><span class="line"><span class="cl">saisei Ready &lt;none&gt; 21s v1.25.0
</span></span></code></pre></div><p>In <a href="https://akenji3.github.io/en/post/20220821_kubernetes_en/">the previous article</a>, another node was added to the cluster configuration, but I didn&rsquo;t this time.</p>
<h4 id="step-4-configure-the-nvdia-software">Step 4: Configure the NVDIA software</h4>
<p>In my environment, the NVIDIA driver is already installed because I have a GPU plugged into the node of control plane. As mentioned in the conclusion, I did not use &ldquo;helm&rdquo; to install the software.</p>
<p>The specific steps are as follows.</p>
<h5 id="1-for-installing-nvidia-container-runtime-package-set-up-nvidia-docker-repository">(1) (for installing nvidia-container-runtime package) Set up nvidia-docker repository</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ <span class="nv">distribution</span><span class="o">=</span><span class="k">$(</span>. /etc/os-release<span class="p">;</span><span class="nb">echo</span> <span class="nv">$ID$VERSION_ID</span><span class="k">)</span> <span class="se">\.</span>
</span></span><span class="line"><span class="cl">   <span class="o">&amp;&amp;</span> curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey <span class="p">|</span> sudo apt-key add - <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>   <span class="o">&amp;&amp;</span> curl -s -L https://nvidia.github.io/nvidia-docker/<span class="nv">$distribution</span>/nvidia-docker.list <span class="p">|</span> sudo tee /etc/apt/sources.list.d/nvidia-docker.list
</span></span></code></pre></div><h5 id="2-install-nvidia-container-runtime-package">(2) Install nvidia-container-runtime package</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ sudo apt-get update \
</span></span><span class="line"><span class="cl">   &amp;&amp; sudo apt-get install -y nvidia-container-runtime
</span></span></code></pre></div><h5 id="3-edit-configtoml">(3) Edit config.toml</h5>
<p>Edit /etc/containerd/config.toml as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">79c79
</span></span><span class="line"><span class="cl">&lt;       <span class="nv">default_runtime_name</span> <span class="o">=</span> <span class="s2">&#34;nvida&#34;</span>
</span></span><span class="line"><span class="cl">---
</span></span><span class="line"><span class="cl">&gt;       <span class="nv">default_runtime_name</span> <span class="o">=</span> <span class="s2">&#34;runc&#34;</span>
</span></span><span class="line"><span class="cl">125,132d124
</span></span><span class="line"><span class="cl">&lt;             <span class="nv">SystemdCgroup</span> <span class="o">=</span> <span class="nb">true</span>
</span></span><span class="line"><span class="cl">&lt;        <span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.nvidia<span class="o">]</span>
</span></span><span class="line"><span class="cl">&lt;           <span class="nv">privileged_without_host_devices</span> <span class="o">=</span> <span class="nb">false</span>
</span></span><span class="line"><span class="cl">&lt;           <span class="nv">runtime_engine</span> <span class="o">=</span> <span class="s2">&#34;&#34;</span>
</span></span><span class="line"><span class="cl">&lt;           <span class="nv">runtime_root</span> <span class="o">=</span> <span class="s2">&#34;&#34;</span>
</span></span><span class="line"><span class="cl">&lt;           <span class="nv">runtime_type</span> <span class="o">=</span> <span class="s2">&#34;io.containerd.runc.v1&#34;</span>
</span></span><span class="line"><span class="cl">&lt;           <span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.nvidia.options<span class="o">]</span>
</span></span><span class="line"><span class="cl">&lt;             <span class="nv">BinaryName</span> <span class="o">=</span> <span class="s2">&#34;/usr/bin/nvidia-container-runtime&#34;</span>
</span></span></code></pre></div><p>Then restart the containerd daemon.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ sudo systemctl restart containerd
</span></span></code></pre></div><h5 id="4-install-nvidia-device-plugin">(4) Install NVIDIA Device Plugin</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.12.3/nvidia-device-plugin.yml
</span></span></code></pre></div><h4 id="step-5-check">Step 5: Check</h4>
<p>Start the GPU pod, check the status, check the logs, and confirm that it is working as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ cat gpu-pod.yaml
</span></span><span class="line"><span class="cl">apiVersion: v1
</span></span><span class="line"><span class="cl">kind: Pod
</span></span><span class="line"><span class="cl">metadata:
</span></span><span class="line"><span class="cl">  name: gpu-operator-test
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  restartPolicy: OnFailure
</span></span><span class="line"><span class="cl">  containers:
</span></span><span class="line"><span class="cl">  - name: cuda-vector-add
</span></span><span class="line"><span class="cl">    image: <span class="s2">&#34;nvidia/samples:vectoradd-cuda10.2&#34;</span>
</span></span><span class="line"><span class="cl">    resources:
</span></span><span class="line"><span class="cl">      limits:
</span></span><span class="line"><span class="cl">         nvidia.com/gpu: <span class="m">1</span>
</span></span><span class="line"><span class="cl">         
</span></span><span class="line"><span class="cl">$ kubectl apply -f gpu-pod.yaml
</span></span><span class="line"><span class="cl">pod/gpu-operator-test created
</span></span><span class="line"><span class="cl">$ kubectl get pods
</span></span><span class="line"><span class="cl">NAME READY STATUS RESTARTS AGE
</span></span><span class="line"><span class="cl">gpu-operator-test 0/1 Completed <span class="m">0</span> 8s
</span></span><span class="line"><span class="cl">$ kubectl logs gpu-operator-test
</span></span><span class="line"><span class="cl"><span class="o">[</span>Vector addition of <span class="m">50000</span> elements<span class="o">]</span>
</span></span><span class="line"><span class="cl">Copy input data from the host memory to the CUDA device
</span></span><span class="line"><span class="cl">CUDA kernel launch with <span class="m">196</span> blocks of <span class="m">256</span> threads
</span></span><span class="line"><span class="cl">Copy output data from the CUDA device to the host memory
</span></span><span class="line"><span class="cl">Test PASSED
</span></span><span class="line"><span class="cl">Done
</span></span></code></pre></div><h2 id="summary">Summary</h2>
<p>However, when another node (mokusei) with GPU is added to the cluster, it does not work on that node and remains in Pending state.</p>
<p>It works while saisei is running, but if I shutdown saisei and start the GPU pod on the cluster, running mokusei node only, it does not work as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ kubectl get nodes
</span></span><span class="line"><span class="cl">NAME STATUS ROLES AGE VERSION
</span></span><span class="line"><span class="cl">europe Ready control-plane 68m v1.25.0
</span></span><span class="line"><span class="cl">mokusei Ready &lt;none&gt; 66m v1.25.0
</span></span><span class="line"><span class="cl">saisei NotReady &lt;none&gt; 9m51s v1.25.0
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ kubectl apply -f gpu-pod.yaml
</span></span><span class="line"><span class="cl">pod/gpu-operator-test created
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ kubectl get pods gpu-operator-test
</span></span><span class="line"><span class="cl">NAME READY STATUS RESTARTS AGE
</span></span><span class="line"><span class="cl">gpu-operator-test 0/1 Pending <span class="m">0</span> 2m50s
</span></span></code></pre></div><p>Next, I&rsquo;m going to resolve the above issues in due course.</p>
<p>Also, I will need to look into specifying the GPU on the node and specifying the certain node together to solve the above problem.</p>
<p>Translated with <a href="http://www.deepl.com/Translator">www.DeepL.com/Translator</a> (free version)</p>


        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20220919_kubernetes_1st_step%2f&amp;text=Building%20a%20GPU%20Cluster%20with%20Kubernetes%20-%20the%20First%20Steps&amp;via=" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20220919_kubernetes_1st_step%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20220919_kubernetes_1st_step%2f&amp;title=Building%20a%20GPU%20Cluster%20with%20Kubernetes%20-%20the%20First%20Steps" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20220919_kubernetes_1st_step%2f&amp;title=Building%20a%20GPU%20Cluster%20with%20Kubernetes%20-%20the%20First%20Steps" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20220919_kubernetes_1st_step%2f&amp;title=Building%20a%20GPU%20Cluster%20with%20Kubernetes%20-%20the%20First%20Steps" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fakenji3.github.io%2fen%2fpost%2f20220919_kubernetes_1st_step%2f&amp;description=Building%20a%20GPU%20Cluster%20with%20Kubernetes%20-%20the%20First%20Steps" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://akenji3.github.io/en/post/20220914_xrandr_badmatch/" data-toggle="tooltip" data-placement="top" title="Change display resolution - xrandr BadMatch support">&larr; Previous Post</a>
            </li>
          
          
            <li class="next">
              <a href="https://akenji3.github.io/en/post/20221230_galaxy_cnn_3/" data-toggle="tooltip" data-placement="top" title="Galaxy Shape Classification by Deep Learning (CNN)（Part 3）">Next Post &rarr;</a>
            </li>
          
        </ul>
      


      

    </div>
  </div>
</div>

      <footer>
  <div class="container">
    
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
          
          
          
        </ul>
        <p class="credits copyright text-muted">
          

          &nbsp;&bull;&nbsp;&copy;
          
            2026
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://akenji3.github.io/en/">akenji&#39;s lab</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.147.1</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js" integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

<script src="https://akenji3.github.io/js/main.js"></script>
<script src="https://akenji3.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://akenji3.github.io/js/load-photoswipe.js"></script>










    
  </body>
</html>

