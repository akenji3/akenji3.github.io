<!DOCTYPE html>
<html lang="ja" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>機械学習レポート - akenji&#39;s lab</title>
  <meta name="description" content="はじめに
この記事に引き続き、JDLA E資格のシラバスの範囲をまとめたもので、今回は「機械学習」に関するもの。">
  <meta name="author" content="Kenji Arai"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "akenji\u0027s lab",
    
    "url": "https:\/\/akenji3.github.io"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/akenji3.github.io"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/akenji3.github.io",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/akenji3.github.io\/post\/20210919_machinelearning\/",
          "name": "機械学習レポート"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Kenji Arai"
  },
  "headline": "機械学習レポート",
  "description" : "はじめに この記事に引き続き、JDLA E資格のシラバスの範囲をまとめたもので、今回は「機械学習」に関するもの。\n",
  "inLanguage" : "ja",
  "wordCount":  8682 ,
  "datePublished" : "2021-09-19T00:00:00",
  "dateModified" : "2021-09-19T00:00:00",
  "image" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
  "keywords" : [ "機械学習" ],
  "mainEntityOfPage" : "https:\/\/akenji3.github.io\/post\/20210919_machinelearning\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/akenji3.github.io",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>

<meta property="og:title" content="機械学習レポート" />
<meta property="og:description" content="はじめに
この記事に引き続き、JDLA E資格のシラバスの範囲をまとめたもので、今回は「機械学習」に関するもの。">
<meta property="og:image" content="https://akenji3.github.io/img/avatar-icon.png" />
<meta property="og:url" content="https://akenji3.github.io/post/20210919_machinelearning/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="akenji&#39;s lab" />

  <meta name="twitter:title" content="機械学習レポート" />
  <meta name="twitter:description" content="はじめに
この記事に引き続き、JDLA E資格のシラバスの範囲をまとめたもので、今回は「機械学習」に関するもの。">
  <meta name="twitter:image" content="https://akenji3.github.io/img/avatar-icon.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@akenji3" />
  <meta name="twitter:creator" content="@akenji3" />
  <link href='https://akenji3.github.io/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.74.3" />
  <link rel="alternate" href="https://akenji3.github.io/index.xml" type="application/rss+xml" title="akenji&#39;s lab"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link rel="stylesheet" href="https://akenji3.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://akenji3.github.io/css/highlight.min.css" /><link rel="stylesheet" href="https://akenji3.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">



<meta name="google-site-verification" content="j8CZGVXeJvndIocFmzuHgNW2yAd7f30cM9gMYPGqDpE" />


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-TGXWYJXF48', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">メニューを切り替え</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://akenji3.github.io">akenji&#39;s lab</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/page/about/">About</a>
            </li>
          
        
          
            <li>
              <a title="Categories" href="/categories">Categories</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/tags">Tags</a>
            </li>
          
        

        
          
            <li>
              
                
                  <a href="/en" lang="en">en</a>
                
              
                
              
            </li>
          
        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="akenji&#39;s lab" href="https://akenji3.github.io">
            <img class="avatar-img" src="https://akenji3.github.io/img/avatar-icon.png" alt="akenji&#39;s lab" />
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>機械学習レポート</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;September 19, 2021に投稿
  
  
  
  
    
      &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Kenji Arai
    
  
  
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <h2 id="はじめに">はじめに</h2>
<p><a href="https://akenji3.github.io/post/20210911_appliedmathematics/">この記事</a>に引き続き、JDLA E資格のシラバスの範囲をまとめたもので、今回は「機械学習」に関するもの。</p>
<h2 id="参考文献">参考文献</h2>
<p>機械学習に関して、自分が使っている参考図書は次の通り。</p>
<ul>
<li>機械学習のエッセンス　加藤公一 著　SBクリエイティブ<br>
→ 教材ビデオの講師が紹介していた。</li>
<li>Pythonによるデータ分析の教科書　寺田学・辻真吾・鈴木たかのり・福島真太郎 著　翔泳社<br>
→ Python3エンジニア認定データ分析試験を受講する際に購入、学習した。</li>
<li>東京大学のデータサイエンティスト育成講座　塚本邦尊・山田典一・大澤文孝 著　マイナビ出版<br>
→ 前回の記事でも紹介した書籍。　今回はChapter 8、9を参照した。</li>
</ul>
<h2 id="線形回帰モデル">線形回帰モデル</h2>
<h3 id="回帰問題">回帰問題</h3>
<p>線形回帰モデルとは、回帰問題（離散あるいは連続値からなる入力するから連続値の出力）を予測する教師あり学習の手法である。</p>
<p>入力データ（説明変数）が１次元の場合を単回帰モデルと言い、多次元の場合を線形重回帰モデルという。幾何学的には、単回帰は直線で表され、重回帰は曲面で表される。</p>
<p>入力ベクトルと未知のパラメータの各要素を掛け・足し合わせた（線型結合；入力とパラメータの内積）もので、表現できる。すなわち次のような目的関数で表される。
$$
y = w_0+ w_1x_1+w_2x_2+ \cdots + w_mx_m
$$
ここで、$y$は目的変数、$w_i$は回帰係数、$x_i$は説明変数と呼ばれる。</p>
<p>上記の目的関数は、次の行列表現でも表される。
$$
\boldsymbol{y} = \boldsymbol{X}\boldsymbol{w}
$$
ここで、$\boldsymbol{x_i} = (1, x_{i1},\cdots,x_{im})^{T}$、$\boldsymbol{y} =(y_1,y_2,\cdots,y_n)^T$、$\boldsymbol{X} =(\boldsymbol{x}_1,\cdots,\boldsymbol{x}_n)^T$、$\boldsymbol{w} =(w_0, w_1,\cdots,w_m)^T$である。$m$は説明変数の数、$n$は入力データ数である。</p>
<h3 id="ハンズオンボストン住宅価格の予測">ハンズオン（ボストン住宅価格の予測）</h3>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 線形回帰モデルのハンズオン</span>
<span class="c1"># scit-learnでデータを読み込む</span>
<span class="c1"># pandasのデータフレームを使用する</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;PRICE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>

<span class="c1"># 説明変数</span>
<span class="n">data2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s1">&#39;CRIM&#39;</span><span class="p">,</span><span class="s1">&#39;RM&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># 目的変数</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s1">&#39;PRICE&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># sklearnのLinearRegressionを使う</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># 線形回帰モデルを取得</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># 学習</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># sklearnのLinearRegressionを使う</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># 線形回帰モデルを取得</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># 学習</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div><p>結果は、次の通り。</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback">array([4.24007956])
</code></pre></div><h4 id="結果に対する考察">結果に対する考察</h4>
<p>説明変数は、犯罪率と部屋数の2つであり、とちらがより価格に効いているか以下で確認した。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 犯罪率：0.3で固定して、部屋数を変えてみる。</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.3、部屋数：3、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span><span class="mi">3</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.3、部屋数：4、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span><span class="mi">4</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.3、部屋数：5、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span><span class="mi">5</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.3、部屋数：6、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span><span class="mi">6</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.3、部屋数：7、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span><span class="mi">7</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.3、部屋数：8、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span><span class="mi">8</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
<span class="c1"># 部屋数：4で固定して、犯罪率を変えてみる。</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.1、部屋数：4、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">4</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.2、部屋数：4、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">4</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.3、部屋数：4、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span><span class="mi">4</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.4、部屋数：4、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span><span class="mi">4</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.5、部屋数：4、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">4</span><span class="p">]])))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;犯罪率：0.6、部屋数：4、価格：{}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span><span class="mi">4</span><span class="p">]])))</span>
</code></pre></div><p>結果は、次の通り、部屋数が価格への寄与度が大である。</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback">犯罪率：0.3、部屋数：3、価格：[-4.15098869]
犯罪率：0.3、部屋数：4、価格：[4.24007956]
犯罪率：0.3、部屋数：5、価格：[12.6311478]
犯罪率：0.3、部屋数：6、価格：[21.02221605]
犯罪率：0.3、部屋数：7、価格：[29.4132843]
犯罪率：0.3、部屋数：8、価格：[37.80435254]

犯罪率：0.1、部屋数：4、価格：[4.29306221]
犯罪率：0.2、部屋数：4、価格：[4.26657088]
犯罪率：0.3、部屋数：4、価格：[4.24007956]
犯罪率：0.4、部屋数：4、価格：[4.21358823]
犯罪率：0.5、部屋数：4、価格：[4.18709691]
犯罪率：0.6、部屋数：4、価格：[4.21358823]
</code></pre></div><p>図を使って上記を表す。以下がそのコード。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 図を使ってみる</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="c1"># 2つのサブプロットで描画する</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;RM&#39;</span><span class="p">]],</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;PRICE&#39;</span><span class="p">]],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Rooms&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Price&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;CRIM&#39;</span><span class="p">]],</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;PRICE&#39;</span><span class="p">]],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Crimes&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Price&#39;</span><span class="p">)</span>
</code></pre></div><p>実行結果は、次の通り。<img src="/images/20210919_MachineLearning/20210918_%E5%88%86%E5%B8%83%E5%9B%B32.png" alt="rooms_crimes_price"></p>
<h2 id="非線形回帰モデル">非線形回帰モデル</h2>
<h3 id="非線形回帰">非線形回帰</h3>
<p>データの構造を線形で捉えられるケースは限られており、データが複雑な分布をもつ現象に対しては、非線形回帰モデルを用いる。そのために、回帰関数として、基底関数と呼ばれる既知の非線形関数とパラメータベクトルの線形結合が用いられる。次のように表現できる。
$$
y_i = w_0 + \sum_{j=1}^m w_j \phi(\boldsymbol{x}_i)
$$
ここで、$\phi()$が基底関数である。基底関数としては、多項式関数、ガウス型基底関数、スプライン関数などがある。</p>
<p>非線形モデルは、線形モデルより高い表現能力を持った予測が行える。しかしながら高い表現能力を持つモデルは、訓練データに過度に適用し、未知のデータに対して適用しない、いわゆる<strong>汎化性能</strong>が低下する問題が発生する。（<strong>過学習</strong>という、訓練誤差小・汎化誤差大の状況に陥る）</p>
<h3 id="テスト手法">テスト手法</h3>
<p>機械学習においては、モデルの精度は、テスト誤差で評価することが大事である。そのため、テストデータを確保し、汎化性能を評価するため、ホールドアウト法、クロスバリデーション（交差検証）などの方法がある。</p>
<p>k分割交差検証（k-fold cross varidation）は、全データを$k$個に分割し、学習も$k$回繰り返す。$i$回目の学習時に$i$番目のサブセットをテストデータとし、残りの$(k-1)$個のサブセットを学習データとして使う手法です。</p>
<h3 id="正則化">正則化</h3>
<p>訓練データに過度に適用し、未知のデータに適用しないという問題を適切に制御（モデルの複雑さを制御）するための仕組みを正則化という。正則化法（罰則化法）は、モデルの複雑さに伴って、その値が大きくなる正則化項を課した関数を最小化する手法である。</p>
<p>正則化項としてL2ノルムを用いるリッジ回帰、L1ノルムを用いるラッソ回帰とがある。</p>
<p><strong>リッジ回帰</strong>においては、正則化係数を十分に大きくすると、いくつかの回帰係数は$0$に近づくが、完全に$0$とはならない。一方、<strong>ラッソ回帰</strong>においては、正則化係数を十分に大きくすると、いくつかの回帰係数は完全に$0$となる。</p>
<h3 id="実装演習用コードを使っての考察">実装演習用コードを使っての考察</h3>
<p>実装演習用のコード「skl_nonlinear regression.ipynb」を使った実行とその評価を以下に述べる。次の図は、KernelRidgeで擬似的に作成したデータから学習した結果のグラフである。<img src="/images/20210919_MachineLearning/20210918_ridge.png" alt="kernelridge"></p>
<p>次に多項式モデルで、上記のデータ（図で青色の点）を予測した結果。但し、1次式（線形）および4次式での予測結果である。4次以上は、4次式の結果とほぼ等しかった。</p>
<p>次のコードの通り、次数をのリストを変更した。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1">#PolynomialFeatures(degree=1)</span>

<span class="c1">#deg = [1,2,3,4,5,6,7,8,9,10]</span>
<span class="n">deg</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">deg</span><span class="p">:</span>
    <span class="n">regr</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">d</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>
    <span class="p">])</span>
    <span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="c1"># make predictions</span>
    <span class="n">p_poly</span> <span class="o">=</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># plot regression result</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">p_poly</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;polynomial of degree </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">d</span><span class="p">))</span>
</code></pre></div><p>上記の結果のグラフは、以下の通りである。<img src="/images/20210919_MachineLearning/20210918_polynominal.png" alt="polynominal"></p>
<p>上記2つのグラフを比較して分かる通り、KernelRidgeでのモデルは、4次式で与えられるデータを上手く予測していることが分かる。</p>
<h2 id="ロジスティック回帰モデル">ロジスティック回帰モデル</h2>
<h3 id="ロジスティック回帰">ロジスティック回帰</h3>
<p>ロジスティック回帰は、「回帰」との名前ではあるが、分類問題に適用されるアルゴリズムである。ロジスティック回帰では、ラベルの値が2種類（$0$または$1$の2つ）しかないような教師あり訓練データに適用される。</p>
<p>与えられた特徴量のサンプル$\boldsymbol{x}\in \mathbb{R}^d$に対して、ラベル$y$が$1$になる確率を$P(Y=1|X=\boldsymbol{x})$で表し、ラベル$y$が$0$になる確率を$P(Y=0|X=\boldsymbol{x})$で表す。ロジスティック回帰は、次の式で表される。
$$
P(Y=1|X=\boldsymbol{x})=\sigma(w_0 + \sum_{j=1}^{d} x_j W_j) = \sigma(\boldsymbol{w}^T \boldsymbol{x}^T)
$$
ここで、$\sigma$はシグモイド関数で、次のように表される。
$$
\sigma(x) = \frac{1}{1+\exp (-ax)}
$$
シグモイド関数の微分は、シグモイド関数自身で表現することが可能である。
$$
\begin{align}
\frac{\partial \sigma(x)}{\partial x} &amp;= \frac{\partial}{\partial x}\left(\frac{1}{1+\exp (-ax)} \right) \\<br>
&amp;= a \sigma(x)(1-\sigma(x))
\end{align}
$$</p>
<p>シグモイド関数は、任意の$\xi$に対して、$0&lt;\sigma(\xi)&lt;1$であり、$\lim_{\xi\to-\infty}=0$、$\lim_{\xi\to\infty}=1$が成り立つ。この性質のため、シグモイド関数は確率として扱えるようになる。</p>
<p>分類問題では、ラベルは$1$か$0$なので、$0$になる確率は$P(Y=0|X=\boldsymbol{x}) = 1 - P(Y=1|X=\boldsymbol{x})$となる。以上をまとめる、ラベルの値が$y$になる確率は次のようになる。
$$
\begin{align}
P(Y=y|X=\boldsymbol{x}) &amp;= P(Y=1|X=\boldsymbol{x})^{y}P(Y=0|X=\boldsymbol{x})^{1-y} \\<br>
&amp;= \sigma(\boldsymbol{x}^T\boldsymbol{w})^y (1-\sigma(\boldsymbol{X}^T \boldsymbol{w}))^{1-y}
\end{align}
$$
上式に$y=1$を代入すると$P(Y=1|X=\boldsymbol{x})=\sigma(\boldsymbol{x}^T\boldsymbol{w})$となり、$y=0$を代入すると$P(Y=0|X=\boldsymbol{x})=1-\sigma(\boldsymbol{x}^T \boldsymbol{w})$となる。</p>
<h3 id="モデルの評価">モデルの評価</h3>
<p>分類問題でのモデルの良し悪しを判断する指標として、適合率（precision）、再現率（recall）、F値（F-Value）、正解率（accuracy）などがある。これらは、以下の混同行列（confusion matrix）から計算できる。</p>
<p><img src="/images/20210919_MachineLearning/20210919_ConfusionMatrix.png" alt="ConfusionMatirx">
$$
\begin{align}
適合率&amp;=\frac{TP}{TP+FP} \\<br>
再現率&amp;=\frac{TP}{TP+FN} \\<br>
正解率&amp;=\frac{TP+TN}{TP+FN+FP+TN}
\end{align}
$$</p>
<h3 id="ハンズオンタイタニック">ハンズオン（タイタニック）</h3>
<p>課題は、次の通り。「年齢が30歳で、男の乗客は生き残れるか？」</p>
<p>タイタニックのデータを読み込み、年齢（Age）がnullの時は、中央値で補間し、特徴量を年齢と性別とし、生き残ったか（Survived）でロジスティック回帰モデルを学習する。学習結果で30歳、男性で生き残る確率を求めた。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># ロジスティック回帰：ハンズオン（タイタニック）</span>
<span class="c1"># 30歳男性の生存は？</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># タイタニックのデータ（ｃｓｖ）を読み込む</span>
<span class="n">titanic_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;study_ai_ml_google/data/titanic_train.csv&#39;</span><span class="p">)</span>

<span class="c1"># 予測に不要と思われるカラムをドロップ</span>
<span class="n">titanic_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;PassengerId&#39;</span><span class="p">,</span> <span class="s1">&#39;Name&#39;</span><span class="p">,</span> <span class="s1">&#39;Ticket&#39;</span><span class="p">,</span> <span class="s1">&#39;Cabin&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Ageカラムのnullを中央値で補間</span>
<span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;AgeFill&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># 文字列の性別を数値化し、Genderカラムに格納</span>
<span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Gender&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;female&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># 年齢と性別のリストを作成</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s1">&#39;AgeFill&#39;</span><span class="p">,</span><span class="s1">&#39;Gender&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># 生死フラグのみのリストを作成</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># ロジスティック回帰のモデルを作成</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="c1"># 学習</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

<span class="c1"># 30歳、男性の生存確率は？</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
</code></pre></div><p>結果は、次の通りとなった。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">array</span><span class="p">([[</span><span class="mf">0.80668102</span><span class="p">,</span> <span class="mf">0.19331898</span><span class="p">]])</span>
</code></pre></div><p>30歳男性が生き残る確率は、19%である。</p>
<h4 id="考察">考察</h4>
<p>次に、サンプルを参考にしながら、実際に動かして、結果を確かめてみた。</p>
<p>先ず、タイタニックデータから、特徴量の性別＋階級（社会階級で、1:high/2:middle/3:low）を合わせた特徴量と年齢（nullは中央値で補間）の２軸で生死をグラフ化する。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># タイタニックのデータ（ｃｓｖ）を読み込む</span>
<span class="n">titanic_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;study_ai_ml_google/data/titanic_train.csv&#39;</span><span class="p">)</span>

<span class="c1"># 予測に不要と思われるカラムをドロップ</span>
<span class="n">titanic_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;PassengerId&#39;</span><span class="p">,</span> <span class="s1">&#39;Name&#39;</span><span class="p">,</span> <span class="s1">&#39;Ticket&#39;</span><span class="p">,</span> <span class="s1">&#39;Cabin&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Ageカラムのnullを中央値で補間</span>
<span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;AgeFill&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># 文字列の性別を数値化し、Genderカラムに格納</span>
<span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Gender&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;female&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1">#  Pclass（階級）とGender（性別）の特徴量を合わせたものを、 Pclass_Gender特徴量とする。</span>
<span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Pclass_Gender&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Pclass&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">titanic_df</span><span class="p">[</span><span class="s1">&#39;Gender&#39;</span><span class="p">]</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">85</span>
<span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">4.5</span>

<span class="n">index_survived</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="p">[</span><span class="n">titanic_df</span><span class="p">[</span><span class="s2">&#34;Survived&#34;</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">index_notsurvived</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="p">[</span><span class="n">titanic_df</span><span class="p">[</span><span class="s2">&#34;Survived&#34;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>

<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu</span>
<span class="n">cm_bright</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">,</span> <span class="s1">&#39;#0000FF&#39;</span><span class="p">])</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index_survived</span><span class="p">,</span> <span class="s1">&#39;AgeFill&#39;</span><span class="p">],</span>
                <span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index_survived</span><span class="p">,</span> <span class="s1">&#39;Pclass_Gender&#39;</span><span class="p">]</span><span class="o">+</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">index_survived</span><span class="p">))</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Not Survived&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index_notsurvived</span><span class="p">,</span> <span class="s1">&#39;AgeFill&#39;</span><span class="p">],</span>
                <span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index_notsurvived</span><span class="p">,</span> <span class="s1">&#39;Pclass_Gender&#39;</span><span class="p">]</span><span class="o">+</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">index_notsurvived</span><span class="p">))</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Survived&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;AgeFill&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Pclass_Gender&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.03</span><span class="p">))</span>
</code></pre></div><p><img src="/images/20210919_MachineLearning/20210919_Titanic_1.png" alt="graph1"></p>
<p>等級＋性別と年齢の特徴量を使って学習し、結果を同じくグラフ化する。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Pclass_Gender（階級＋性別）とAgeFill（補間した年齢）のリスト作成</span>
<span class="n">data2</span> <span class="o">=</span> <span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&#34;AgeFill&#34;</span><span class="p">,</span> <span class="s2">&#34;Pclass_Gender&#34;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1">#　生死フラグのみのリストを作成</span>
<span class="n">label2</span> <span class="o">=</span>  <span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s2">&#34;Survived&#34;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># ロジスティック回帰のモデルを作成</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="c1"># 学習</span>
<span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="n">label2</span><span class="p">)</span>

<span class="n">h</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">85</span>
<span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">4.5</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu</span>
<span class="n">cm_bright</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">,</span> <span class="s1">&#39;#0000FF&#39;</span><span class="p">])</span>
<span class="c1">#contour = ax.contourf(xx, yy, Z, cmap=cm, levels=levels, alpha=0.5)</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index_survived</span><span class="p">,</span> <span class="s1">&#39;AgeFill&#39;</span><span class="p">],</span>
                <span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index_survived</span><span class="p">,</span> <span class="s1">&#39;Pclass_Gender&#39;</span><span class="p">]</span><span class="o">+</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">index_survived</span><span class="p">))</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Not Survived&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index_notsurvived</span><span class="p">,</span> <span class="s1">&#39;AgeFill&#39;</span><span class="p">],</span>
                <span class="n">titanic_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index_notsurvived</span><span class="p">,</span> <span class="s1">&#39;Pclass_Gender&#39;</span><span class="p">]</span><span class="o">+</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">index_notsurvived</span><span class="p">))</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Survived&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;AgeFill&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Pclass_Gender&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>
<span class="c1">#fig.colorbar(contour)</span>

<span class="n">x1</span> <span class="o">=</span> <span class="n">xmin</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">xmax</span>
<span class="n">y1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">model2</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">xmin</span><span class="p">)</span><span class="o">/</span><span class="n">model2</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">model2</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">xmax</span><span class="p">)</span><span class="o">/</span><span class="n">model2</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">]</span> <span class="p">,[</span><span class="n">y1</span><span class="p">,</span> <span class="n">y2</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
</code></pre></div><p><img src="/images/20210919_MachineLearning/20210919_Titanic_2.png" alt="Titanic_2"></p>
<p>上記の結果、年齢が高く、階級が低い程（ Pclassの値は大きくなる）、死亡する割合が多くなる傾向となることが判る。</p>
<h2 id="主成分分析">主成分分析</h2>
<p>主成分分析（Principal Component Analysis; PCA）は、教師なし学習の一種であり、次元圧縮の手法である。PCAにより多変量データを持つ構造をより少数個の指標に圧縮する。圧縮された少数の変数を利用した分析に使われたり、2、3の変数に圧縮することで、可視化（２次元、３次元）に使われる。</p>
<p>PCAは与えられたデータをより低次元の空間に射影し、射影後の点の散らばりができるだけ大きくなるようにする。すなわち、情報損失が小さくなるように、分散が最大になる方向に射影すれよい。</p>
<p>第一主成分は、データの共分散行列の最大固有値を与える固有ベクトルである。すなわち、主成分問題=固有値問題となる。</p>
<h3 id="ハンズオン乳がん検査データ">ハンズオン（乳がん検査データ）</h3>
<p>まずは、データを読み込む。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># 乳がん検査データを読み込む</span>
<span class="n">cancer_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;study_ai_ml_google/data/cancer.csv&#39;</span><span class="p">)</span>

<span class="c1">#　データの個数と次元数を確認</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;cancer df shape: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer_df</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">cancer_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Unnamed: 32&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cancer_df</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;cancer df shape: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer_df</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</code></pre></div><p>読み込んだデータのレコード数と次元（カラム数）</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cancer</span> <span class="n">df</span> <span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="mi">569</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span>
<span class="n">cancer</span> <span class="n">df</span> <span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="mi">569</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
</code></pre></div><p>ロジスティック回帰で学習し、学習データ、テストデータでの精度、および混同行列を出力する。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 目的変数の抽出</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">cancer_df</span><span class="o">.</span><span class="n">diagnosis</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="s1">&#39;M&#39;</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># 説明変数の抽出</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">cancer_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;radius_mean&#39;</span><span class="p">:]</span>

<span class="c1"># 学習用とテスト用でデータを分離</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># 標準化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># ロジスティック回帰で学習</span>
<span class="n">logistic</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">logistic</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 検証</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Train score: {:.3f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logistic</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Test score: {:.3f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logistic</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Confustion matrix:</span><span class="se">\n</span><span class="s1">{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">logistic</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">))))</span>
</code></pre></div><p>検証結果は、以下の通り。テストデータで97%の精度で分類できている。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">Train</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.988</span>
<span class="n">Test</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.972</span>
<span class="n">Confustion</span> <span class="n">matrix</span><span class="p">:</span>
<span class="p">[[</span><span class="mi">89</span>  <span class="mi">1</span><span class="p">]</span>
 <span class="p">[</span> <span class="mi">3</span> <span class="mi">50</span><span class="p">]]</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
</code></pre></div><p><img src="/images/20210919_MachineLearning/20210919_PCA_1.png" alt="PCA_1"></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># PCA</span>
<span class="c1"># 次元数2まで圧縮</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;X_train_pca shape: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train_pca</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="c1"># X_train_pca shape: (426, 2)</span>

<span class="c1"># 寄与率</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;explained variance ratio: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">))</span>
<span class="c1"># explained variance ratio: [ 0.43315126  0.19586506]</span>

<span class="c1"># 散布図にプロット</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">)</span>
<span class="n">temp</span><span class="p">[</span><span class="s1">&#39;Outcome&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">temp</span><span class="p">[</span><span class="n">temp</span><span class="p">[</span><span class="s1">&#39;Outcome&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">temp</span><span class="p">[</span><span class="n">temp</span><span class="p">[</span><span class="s1">&#39;Outcome&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span> <span class="c1"># 良性は○でマーク</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;^&#39;</span><span class="p">)</span> <span class="c1"># 悪性は△でマーク</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;PC 1&#39;</span><span class="p">)</span> <span class="c1"># 第1主成分をx軸</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;PC 2&#39;</span><span class="p">)</span> <span class="c1"># 第2主成分をy軸</span>
</code></pre></div><p>このコードの出力結果は、次の通り。第1成分の寄与度が0.433、第2成分の寄与度が0.196である。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_train_pca</span> <span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="mi">426</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">explained</span> <span class="n">variance</span> <span class="n">ratio</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.43315126</span> <span class="mf">0.19586506</span><span class="p">]</span>
</code></pre></div><p><img src="/images/20210919_MachineLearning/20210919_PCA_2.png" alt="PCA_2"></p>
<h2 id="アルゴリズム">アルゴリズム</h2>
<p>この章では、k近傍法（k-nearest neighbor algorithm; k-NN）とk平均法（k-means clustering）とを説明する。冒頭に&quot;k&quot;がついて混同しがちであるが、k近傍法は、教師ありの分類のためのアルゴリズムであり、k平均法は、教師なしのクラスタリングのアルゴリズムである。</p>
<h3 id="k近傍法knn">k近傍法（kNN）</h3>
<p>与えられた学習データをベクトル空間上にプロットしておき、未知のデータが得られたら、そこから距離が近い順に任意の<strong>k</strong>個を取得し、その多数決でデータが属するクラスを推定するというもの。 分類のアルゴリズムの中でも、シンプルでわかりやすいアルゴリズムである。</p>
<p>kを変化させると結果も変わる。また、kを大きくすると決定境界は滑らかになる。特にkが1の時を最近傍法ともいう。</p>
<h3 id="k平均法k-means">k平均法（k-means）</h3>
<p>与えられたデータをk個のクラスタに分類する。k平均法のアルゴリズムは次のようなステップからなる。</p>
<ol>
<li>各クラスタ中心の初期値を設定する。</li>
<li>各データ点に対して、各クラスタ中心との距離を計算し、最も距離が近いクラスタを割り当てる。</li>
<li>各クラスタの平均ベクトル（重心）を計算する。</li>
<li>収束するまで、ステップ2、3の処理を繰り返す。</li>
</ol>
<p>結果は、初期値のクラスタのランダムな割り振りに大きく依存することが知られており、1回の結果で最良のものが得られるとは限らない。そのため、何度か繰り返して行って最良の結果を選択する手法や、k-means++法のように初期値のクラスタ重心（セントロイド）同士の距離がなるべく遠くになるように改良した手法などが使用されることがある。</p>
<h3 id="ハンズオンk近傍法">ハンズオン（k近傍法）</h3>
<h4 id="データを作成">データを作成</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># ｋ近傍法</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># 訓練データを作成</span>
<span class="k">def</span> <span class="nf">gen_data</span><span class="p">():</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">])</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">25</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">25</span><span class="p">)])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">ys_train</span> <span class="o">=</span> <span class="n">gen_data</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">ys_train</span><span class="p">)</span>
</code></pre></div><p><img src="/images/20210919_MachineLearning/20210919_kNN_1.png" alt="kNN_1"></p>
<h4 id="決定境界を描く">決定境界を描く</h4>
<p>上記で与えられたデータの決定境界を決め、プロットする。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">knc_predict</span><span class="p">(</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">y_train</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X_test</span><span class="p">):</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="n">distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span>
        <span class="n">nearest_index</span> <span class="o">=</span> <span class="n">distances</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:</span><span class="n">n_neighbors</span><span class="p">]</span>
        <span class="n">mode</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">nearest_index</span><span class="p">])</span>
        <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="k">return</span> <span class="n">y_pred</span>

<span class="k">def</span> <span class="nf">plt_resut</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">xx0</span><span class="p">,</span> <span class="n">xx1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xx0</span><span class="p">,</span> <span class="n">xx1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx0</span><span class="p">,</span> <span class="n">xx1</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</code></pre></div><p>k=3の時の決定境界をプロットする。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">xx0</span><span class="p">,</span> <span class="n">xx1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xx0</span><span class="p">,</span> <span class="n">xx1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knc_predict</span><span class="p">(</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">ys_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
<span class="n">plt_resut</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">ys_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</code></pre></div><p><img src="/images/20210919_MachineLearning/20210919_kNN_2.png" alt="kNN_2"></p>
<p>「n_neighbors = 3」を「n_neighbors = 8」とした時の決定境界をプロットしたものが以下の通り。<img src="/images/20210919_MachineLearning/20210919_kNN_3.png" alt="kNN_3"></p>
<p>上記の2つのプロットを比べてみると、kが大きい方が、決定境界が滑らかになることが分かる。</p>
<h2 id="サポートベクターマシーン">サポートベクターマシーン</h2>
<h3 id="svmハードマージンソフトマージン">SVM（ハードマージン・ソフトマージン）</h3>
<p>サポートベクターマシン（Support Vector Machine; SVM）は、教師あり学習であり、分類にも回帰にも使われるが、2値分類に使われることが多い。</p>
<p>2値分類においては、データ点$\boldsymbol{x}$を$y(x)=\boldsymbol{w}^T\phi(\boldsymbol{x})+b$の正負によって分類する。$\phi(\boldsymbol{x})$は特徴ベクトル。</p>
<p>境界$y(x)=\boldsymbol{w}^T\phi(\boldsymbol{x})+b=0$によって、各クラスのデータを分類する。各クラスのデータ点と境界との最短距離をマージンと呼ぶ。SVMでは、マージンが最大となる境界$y(x)=\boldsymbol{w}^T\phi(\boldsymbol{x})+b(=0)$におけるバラメータ$\boldsymbol{w},b$を学習する。この時、マージン上にある点をサポートベクトルと呼ぶ。</p>
<p>ソフトマージン（ある程度分類誤りを許容する）においては、マージン内に誤分類された時に正の値をとるスラック変数を導入して、次のように目的関数を表現する。
$$
目的関数 \equiv C \sum_{i=1}^{n}\xi_i + \frac{1}{2}||\boldsymbol{w}||^2 \sim \frac{1}{2}\boldsymbol{w}^T \boldsymbol{w} + \sum_{i=1}^{n} \xi_i
$$
上式においては、次のようなことが言える。</p>
<ul>
<li>$C\to\infty$の時は、マージン内に訓練データが入ることや誤分類を一切許容しない。</li>
<li>$C=\to0$の時は、誤分類が多くなる。</li>
<li>一般に過学習を防ぐためには、$C$を小さくする方がよい。</li>
<li>$\xi_i=0$の時、ハードマージンSVMである。</li>
<li>$\xi_i &gt; 1$の時、超平面による分類に失敗している。</li>
</ul>
<h3 id="ハンズオン">ハンズオン</h3>
<p>ソフトマージンSVMのコードを試し、上記の$C$の値を変化させた時の振る舞いについて調べる。</p>
<p>テストデータは、次のように得る。それを可視化したグラフを以下に掲載する。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># サポートベクターマシン</span>
<span class="c1"># ソフトマージンSVMを試す</span>

<span class="c1"># テストデータの作成と描画</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">25</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">25</span><span class="p">)])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
</code></pre></div><p><img src="/images/20210919_MachineLearning/20210920_SVM_1.png" alt="SVM_1"></p>
<p>次に学習と予測のコードは次のとおり。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 学習</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">x_train</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="c1"># 線形カーネル</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="n">C</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">eta1</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">eta2</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">n_iter</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">K</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">H</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">+=</span> <span class="n">eta1</span> <span class="o">*</span> <span class="n">grad</span>
    <span class="n">a</span> <span class="o">-=</span> <span class="n">eta2</span> <span class="o">*</span> <span class="n">a</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>

<span class="c1"># 予測</span>

<span class="n">index</span> <span class="o">=</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="mf">1e-8</span>
<span class="n">support_vectors</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="n">support_vector_t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="n">support_vector_a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

<span class="n">term2</span> <span class="o">=</span> <span class="n">K</span><span class="p">[</span><span class="n">index</span><span class="p">][:,</span> <span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">support_vector_a</span> <span class="o">*</span> <span class="n">support_vector_t</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="n">support_vector_t</span> <span class="o">-</span> <span class="n">term2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div><p>以下が可視化（描画）のコードと描画結果<img src="/images/20210919_MachineLearning/20210920_SVM_C1.png" alt="SVM_C1"></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 可視化準備と可視化（描画）</span>
<span class="n">xx0</span><span class="p">,</span> <span class="n">xx1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xx0</span><span class="p">,</span> <span class="n">xx1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">xx</span>
<span class="n">y_project</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span> <span class="o">*</span> <span class="n">b</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">sv_t</span><span class="p">,</span> <span class="n">sv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">support_vector_a</span><span class="p">,</span> <span class="n">support_vector_t</span><span class="p">,</span> <span class="n">support_vectors</span><span class="p">):</span>
        <span class="n">y_project</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">sv_t</span> <span class="o">*</span> <span class="n">sv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y_project</span><span class="p">)</span>

<span class="c1"># 訓練データを可視化</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
<span class="c1"># サポートベクトルを可視化</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">support_vectors</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">support_vectors</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="c1"># 領域を可視化</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx0</span><span class="p">,</span> <span class="n">xx1</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="c1"># マージンと決定境界を可視化</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xx0</span><span class="p">,</span> <span class="n">xx1</span><span class="p">,</span> <span class="n">y_project</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
                     <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">])</span>
</code></pre></div><p>次に、学習時に「C = 1」とパラメータ設定した部分を、「C = 0.1」と「C = 10」とした場合の可視化結果を示す。</p>
<p><img src="/images/20210919_MachineLearning/20210920_SVM_C01.png" alt="SVM_C01"></p>
<p><img src="/images/20210919_MachineLearning/20210920_SVM_C10.png" alt="SVM_C10"></p>
<p>以上のように、Cを大きくすると、決定境界とマージンとの距離が小さくなり、誤分類を許さない方向にコントロールされることが分かる。</p>

        
          <div class="blog-tags">
            
              <a href="https://akenji3.github.io/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/">機械学習</a>&nbsp;
            
          </div>
        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20210919_machinelearning%2f&amp;text=%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88&amp;via=akenji3" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fakenji3.github.io%2fpost%2f20210919_machinelearning%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20210919_machinelearning%2f&amp;title=%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20210919_machinelearning%2f&amp;title=%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20210919_machinelearning%2f&amp;title=%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20210919_machinelearning%2f&amp;description=%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://akenji3.github.io/post/20210912_display_inline_math/" data-toggle="tooltip" data-placement="top" title="ブログ記事でインライン形式の数式を表示させる">&larr; 前ページ</a>
            </li>
          
          
        </ul>
      


      

    </div>
  </div>
</div>

      
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:akenji.1118@gmail.com" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://www.facebook.com/arai.kenji3" title="Facebook">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-facebook fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://github.com/akenji3" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/akenji3" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/kenji-arai-0547aa1a4" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            <a href="" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fas fa-circle fa-stack-2x"></i>
                <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              Kenji Arai
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2021
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://akenji3.github.io">akenji&#39;s lab</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          起動力に<a href="https://gohugo.io">Hugo v0.74.3</a> &nbsp;&bull;&nbsp; テーマに<a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a>に基づいている<a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="https://akenji3.github.io/js/main.js"></script>
<script src="https://akenji3.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script> renderMathInElement(document.body); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://akenji3.github.io/js/load-photoswipe.js"></script>








<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']]
  }
});
</script>


    
  </body>
</html>

