<!DOCTYPE html>
<html lang="ja" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>LlamaIndexを使ってRAGを試す - akenji&#39;s lab</title>
  <meta name="description" content="モチベーション
Chatbot UIを試したこの投稿で、今後挑戦したいことの一つにRAG（Retrieval Augmented Generation）との連携と述べた。この投稿ではLlamaIndexを使ってRAGを実現する方法についてまとめた。
実は昨年末にLangchainを使ってRAGを試してみた。その後、LlamaIndexとのキーワードを良く聞いてきたので、今回LlamaIndexを使ってRAGを実現することにした。">
  <meta name="author" content="Kenji Arai"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "akenji\u0027s lab",
    
    "url": "https:\/\/akenji3.github.io"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/akenji3.github.io"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/akenji3.github.io",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/akenji3.github.io\/post\/20240525_llamaindex_rag\/",
          "name": "Llama indexを使って r a gを試す"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Kenji Arai"
  },
  "headline": "LlamaIndexを使ってRAGを試す",
  "description" : "モチベーション Chatbot UIを試したこの投稿で、今後挑戦したいことの一つにRAG（Retrieval Augmented Generation）との連携と述べた。この投稿ではLlamaIndexを使ってRAGを実現する方法についてまとめた。\n実は昨年末にLangchainを使ってRAGを試してみた。その後、LlamaIndexとのキーワードを良く聞いてきたので、今回LlamaIndexを使ってRAGを実現することにした。\n",
  "inLanguage" : "ja",
  "wordCount":  2278 ,
  "datePublished" : "2024-05-25T00:00:00",
  "dateModified" : "2024-05-25T00:00:00",
  "image" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
  "keywords" : [ "" ],
  "mainEntityOfPage" : "https:\/\/akenji3.github.io\/post\/20240525_llamaindex_rag\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/akenji3.github.io",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/akenji3.github.io\/img\/avatar-icon.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>

<meta property="og:title" content="LlamaIndexを使ってRAGを試す" />
<meta property="og:description" content="モチベーション
Chatbot UIを試したこの投稿で、今後挑戦したいことの一つにRAG（Retrieval Augmented Generation）との連携と述べた。この投稿ではLlamaIndexを使ってRAGを実現する方法についてまとめた。
実は昨年末にLangchainを使ってRAGを試してみた。その後、LlamaIndexとのキーワードを良く聞いてきたので、今回LlamaIndexを使ってRAGを実現することにした。">
<meta property="og:image" content="https://akenji3.github.io/img/avatar-icon.png" />
<meta property="og:url" content="https://akenji3.github.io/post/20240525_llamaindex_rag/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="akenji&#39;s lab" />

  <meta name="twitter:title" content="LlamaIndexを使ってRAGを試す" />
  <meta name="twitter:description" content="モチベーション
Chatbot UIを試したこの投稿で、今後挑戦したいことの一つにRAG（Retrieval Augmented Generation）との連携と述べた。この投稿ではLlamaIndexを使ってRAGを実現する方法についてまとめた。
実は昨年末にLangchainを使ってRAGを試してみた。その後、LlamaIndexとのキーワードを良く聞いてきたので、今回LlamaIndexを使 …">
  <meta name="twitter:image" content="https://akenji3.github.io/img/avatar-icon.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@akenji3" />
  <meta name="twitter:creator" content="@akenji3" />
  <link href='https://akenji3.github.io/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.74.3" />
  <link rel="alternate" href="https://akenji3.github.io/index.xml" type="application/rss+xml" title="akenji&#39;s lab"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link rel="stylesheet" href="https://akenji3.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://akenji3.github.io/css/highlight.min.css" /><link rel="stylesheet" href="https://akenji3.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">



<meta name="google-site-verification" content="j8CZGVXeJvndIocFmzuHgNW2yAd7f30cM9gMYPGqDpE" />


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-TGXWYJXF48', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">メニューを切り替え</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://akenji3.github.io">akenji&#39;s lab</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/page/about/">About</a>
            </li>
          
        
          
            <li>
              <a title="Categories" href="/categories">Categories</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/tags">Tags</a>
            </li>
          
        

        
          
            <li>
              
                
                  <a href="/en" lang="en">en</a>
                
              
                
              
            </li>
          
        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="akenji&#39;s lab" href="https://akenji3.github.io">
            <img class="avatar-img" src="https://akenji3.github.io/img/avatar-icon.png" alt="akenji&#39;s lab" />
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>LlamaIndexを使ってRAGを試す</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;May 25, 2024に投稿
  
  
  
  
    
      &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Kenji Arai
    
  
  &nbsp;&bull;&nbsp;翻訳：<a href="https://akenji3.github.io/en/post/20240525_llamaindex_rag/" lang="en">en</a>
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <h2 id="モチベーション">モチベーション</h2>
<p>Chatbot UIを試した<a href="https://akenji3.github.io/post/20240506_llamaserver/">この投稿</a>で、今後挑戦したいことの一つにRAG（Retrieval Augmented Generation）との連携と述べた。この投稿ではLlamaIndexを使ってRAGを実現する方法についてまとめた。</p>
<p>実は昨年末にLangchainを使ってRAGを試してみた。その後、LlamaIndexとのキーワードを良く聞いてきたので、今回LlamaIndexを使ってRAGを実現することにした。</p>
<h2 id="情報源">情報源</h2>
<ol>
<li><a href="https://tech.dentsusoken.com/entry/2024/01/22/LlamaIndex%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E7%92%B0%E5%A2%83%E3%81%A7RAG%E3%82%92%E5%AE%9F%E8%A1%8C%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95">LlamaIndexを使ってローカル環境でRAGを実行する方法</a>  この記事の内容（コード、RAGのための付加情報も含め）をそのまま使った。この記事は今年の1月に書かれたもので、LlamaIndexのバージョンアップする前のコードで記述されており、その部分は変更する必要あり。</li>
<li><a href="https://note.com/alexweberk/n/n3cffc010e9e9">LangChainを使ったRAGをElyza 7bを用いて試したみた</a>  昨年の年末休暇時に、RAGを試そうとして参考にした記事。</li>
<li><a href="https://qiita.com/miyamotok0105/items/9f5d1fc8b92e3447a75f">ImportError: cannot import name &lsquo;SimpleDirectoryReader&rsquo; from &lsquo;llama_index&rsquo; (unknown location)</a>  llama-indexのバージョン変更に伴いライブラリの構成が見直されたため、過去のバージョンのpythonコードだとエラーが出る。</li>
<li><a href="https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo/">Web Page Reader</a>  情報源1.ではテキストデータを埋め込みモデルのデータとして使用したが、Webページの情報を埋め込みモデルにするヒントが書かれている。</li>
</ol>
<h2 id="llamaindexでの実装">LlamaIndexでの実装</h2>
<h4 id="dockerfile">Dockerfile</h4>
<p>Dockerfileの前半部分は、情報源1.を参考にし、pythonライブラリを組み込む部分は、<a href="https://akenji3.github.io/post/20240503_llama-cpp-python/">この投稿</a>で使ったDockerfileから大部分を流用した。</p>
<p>「pip install llama-index」より前の２行は、llama_indexがv0.10.0以上の場合に必要となる。</p>
<div class="highlight"><pre class="chroma"><code class="language-dockerfile" data-lang="dockerfile"><span class="k">FROM</span><span class="s"> nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Set bash as the default shell</span><span class="err">
</span><span class="err"></span><span class="k">ENV</span> <span class="nv">SHELL</span><span class="o">=</span>/bin/bash<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Build with some basic utilities</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> apt update <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> apt install -y <span class="se">\
</span><span class="se"></span>        wget <span class="se">\
</span><span class="se"></span>        bzip2 <span class="se">\
</span><span class="se"></span>        git <span class="se">\
</span><span class="se"></span>        git-lfs <span class="se">\
</span><span class="se"></span>        curl <span class="se">\
</span><span class="se"></span>        unzip <span class="se">\
</span><span class="se"></span>        file <span class="se">\
</span><span class="se"></span>        xz-utils <span class="se">\
</span><span class="se"></span>        sudo <span class="se">\
</span><span class="se"></span>        python3 <span class="se">\
</span><span class="se"></span>        python3-pip <span class="o">&amp;&amp;</span> <span class="se">\
</span><span class="se"></span>        apt-get autoremove -y <span class="o">&amp;&amp;</span> <span class="se">\
</span><span class="se"></span>        apt-get clean <span class="o">&amp;&amp;</span> <span class="se">\
</span><span class="se"></span>        rm -rf /usr/local/src/*<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># alias python=&#39;python3&#39;</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> ln -s /usr/bin/python3 /usr/bin/python<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> pip install --upgrade pip setuptools <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install <span class="nv">torch</span><span class="o">==</span>2.2.2 <span class="nv">torchvision</span><span class="o">==</span>0.17.2 <span class="nv">torchaudio</span><span class="o">==</span>2.2.2 <span class="se">\
</span><span class="se"></span>	--index-url https://download.pytorch.org/whl/cu121 <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install jupyterlab matplotlib pandas scikit-learn ipywidgets <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install transformers accelerate sentencepiece einops <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install langchain bitsandbytes protobuf <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install auto-gptq optimum <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install pypdf sentence-transformers <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install llama-index-embeddings-huggingface llama-index-llms-openai <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install llama-index-llms-llama-cpp <span class="se">\
</span><span class="se"></span>	<span class="o">&amp;&amp;</span> pip install llama-index<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Install llama-cpp-python[server] with cuBLAS on</span><span class="err">
</span><span class="err"></span><span class="k">RUN</span> <span class="nv">CMAKE_ARGS</span><span class="o">=</span><span class="s2">&#34;-DLLAMA_CUBLAS=on&#34;</span> <span class="nv">FORCE_CMAKE</span><span class="o">=</span><span class="m">1</span> <span class="se">\
</span><span class="se"></span>        pip install llama-cpp-python<span class="o">[</span>server<span class="o">]</span> --force-reinstall --no-cache-dir<span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Create a working directory</span><span class="err">
</span><span class="err"></span><span class="k">WORKDIR</span><span class="s"> /workdir</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="c"># Port number in container side</span><span class="err">
</span><span class="err"></span><span class="k">EXPOSE</span><span class="s"> 8888</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">ENTRYPOINT</span> <span class="p">[</span><span class="s2">&#34;jupyter-lab&#34;</span><span class="p">,</span> <span class="s2">&#34;--ip=0.0.0.0&#34;</span><span class="p">,</span> <span class="s2">&#34;--port=8888&#34;</span><span class="p">,</span> <span class="s2">&#34;--no-browser&#34;</span><span class="p">,</span> <span class="s2">&#34;--allow-root&#34;</span><span class="p">,</span> <span class="s2">&#34;--NotebookApp.token=&#39;&#39;&#34;</span><span class="p">]</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">CMD</span> <span class="p">[</span><span class="s2">&#34;--notebook-dir=/workdir&#34;</span><span class="p">]</span><span class="err">
</span></code></pre></div><p>上記のDockerfileで作成されたコンテナのpip listの抜粋。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">llama_cpp_python                        0.2.75
llama-index                             0.10.38
llama-index-agent-openai                0.2.5
llama-index-cli                         0.1.12
llama-index-core                        0.10.38.post2
llama-index-embeddings-huggingface      0.2.0
llama-index-embeddings-openai           0.1.10
llama-index-indices-managed-llama-cloud 0.1.6
llama-index-legacy                      0.9.48
llama-index-llms-llama-cpp              0.1.3
llama-index-llms-openai                 0.1.20
llama-index-multi-modal-llms-openai     0.1.6
llama-index-program-openai              0.1.6
llama-index-question-gen-openai         0.1.3
llama-index-readers-file                0.1.22
llama-index-readers-llama-parse         0.1.4

torch                                   2.2.2+cu121
torchaudio                              2.2.2+cu121
torchvision                             0.17.2+cu121
</code></pre></div><h4 id="pythonソースの変更箇所">pythonソースの変更箇所</h4>
<p>Dockerfileのところでも触れたが、llama_indexがv0.10.0でライブラリ構成が変更になり、以前のコードだと次のとおりエラーになる。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">---------------------------------------------------------------------------</span>
<span class="ne">ImportError</span>                               <span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">)</span>
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">5</span>
      <span class="mi">2</span> <span class="kn">import</span> <span class="nn">os</span>
      <span class="mi">3</span> <span class="kn">import</span> <span class="nn">sys</span>
<span class="o">----&gt;</span> <span class="mi">5</span> <span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="p">(</span>
      <span class="mi">6</span>     <span class="n">LLMPredictor</span><span class="p">,</span>
      <span class="mi">7</span>     <span class="n">PromptTemplate</span><span class="p">,</span>
      <span class="mi">8</span>     <span class="n">ServiceContext</span><span class="p">,</span>
      <span class="mi">9</span>     <span class="n">SimpleDirectoryReader</span><span class="p">,</span>
     <span class="mi">10</span>     <span class="n">VectorStoreIndex</span><span class="p">,</span>
     <span class="mi">11</span> <span class="p">)</span>
     <span class="mi">12</span> <span class="kn">from</span> <span class="nn">llama_index.callbacks</span> <span class="kn">import</span> <span class="n">CallbackManager</span><span class="p">,</span> <span class="n">LlamaDebugHandler</span>
     <span class="mi">13</span> <span class="kn">from</span> <span class="nn">llama_index.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbedding</span>

<span class="ne">ImportError</span><span class="p">:</span> <span class="n">cannot</span> <span class="kn">import</span> <span class="nn">name</span> <span class="s1">&#39;LLMPredictor&#39;</span> <span class="kn">from</span> <span class="s1">&#39;llama_index&#39;</span> <span class="p">(</span><span class="n">unknown</span> <span class="n">location</span><span class="p">)</span>
</code></pre></div><p>そこで、次のように修正した。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="s2">&#34;&#34;&#34;
</span><span class="s2">from llama_index import (
</span><span class="s2">    LLMPredictor,
</span><span class="s2">    PromptTemplate,
</span><span class="s2">    ServiceContext,
</span><span class="s2">    SimpleDirectoryReader,
</span><span class="s2">    VectorStoreIndex,
</span><span class="s2">)
</span><span class="s2">
</span><span class="s2">from llama_index.callbacks import CallbackManager, LlamaDebugHandler
</span><span class="s2">from llama_index.embeddings import HuggingFaceEmbedding
</span><span class="s2">from llama_index.llms import LlamaCPP
</span><span class="s2">&#34;&#34;&#34;</span>
<span class="kn">from</span> <span class="nn">llama_index.legacy</span> <span class="kn">import</span> <span class="n">LLMPredictor</span>
<span class="kn">from</span> <span class="nn">llama_index.core.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">from</span> <span class="nn">llama_index.core</span> <span class="kn">import</span> <span class="n">ServiceContext</span><span class="p">,</span> <span class="n">SimpleDirectoryReader</span><span class="p">,</span> <span class="n">VectorStoreIndex</span>

<span class="kn">from</span> <span class="nn">llama_index.core.callbacks</span> <span class="kn">import</span> <span class="n">CallbackManager</span><span class="p">,</span> <span class="n">LlamaDebugHandler</span>
<span class="kn">from</span> <span class="nn">llama_index.embeddings.huggingface</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbedding</span>
<span class="kn">from</span> <span class="nn">llama_index.llms.llama_cpp</span> <span class="kn">import</span> <span class="n">LlamaCPP</span>

<span class="c1"># ログレベルの設定</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><p>LLMのパスを指定するf文字列の部分は、自分の環境に合わせて次のようにした。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model_path</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&#34;../20240421_llamacpp/ELYZA-japanese-Llama-2-7b-fast-instruct-q4_K_M.gguf&#34;</span>
</code></pre></div><p>GPUを使うために、n_gpu_layersの箇所を</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python">    <span class="n">model_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;n_ctx&#34;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">,</span> <span class="s2">&#34;n_gpu_layers&#34;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">},</span>
</code></pre></div><p>さらにEMBEDDING_DEVICEの箇所を</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback">EMBEDDING_DEVICE = &#34;cuda&#34;
</code></pre></div><p>に変更した。</p>
<p>その他、記事の説明では、chunk_sizeを512に設定したと、あったので以下の通り変更した。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python">    <span class="n">chunk_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</code></pre></div><p>その他は、情報源1.のコードをそのまま使った。</p>
<h4 id="動作について">動作について</h4>
<p>コードを実行すると、LLM（ggufで量子化されたElyzaモデル）を読み込み、RAGの埋め込みモデル、インデックスを作成し終わるまで、5分程度待った。</p>
<p>質問を投げると、2、3秒で回答が返ってきた。</p>
<p>回答を返す際には、GPU使用率は60〜70%程度だった。RTX A4000（16GB）、TITAN V（12GB）の両方で動作した。GPUメモリは9GB程度使用していた。</p>
<h4 id="webページから埋め込みモデルを作る">Webページから埋め込みモデルを作る</h4>
<p>今回試した情報源1.では、テキストデータを埋め込みモデルに使う方法であった。WikipediaなどのWebページのデータを使う方法を情報源4.を参考に更に試した。</p>
<p>Webページとしては、<a href="https://ja.wikipedia.org/wiki/R%E9%81%8E%E7%A8%8B">r過程</a>のページを使用した。次のセルを</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># ドキュメントの読み込み</span>
<span class="n">documents</span> <span class="o">=</span> <span class="n">SimpleDirectoryReader</span><span class="p">(</span><span class="s2">&#34;data&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</code></pre></div><p>以下のように変更した。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">target_url</span> <span class="o">=</span> <span class="s2">&#34;https://ja.wikipedia.org/wiki/R</span><span class="si">%E</span><span class="s2">9</span><span class="si">%81%</span><span class="s2">8E</span><span class="si">%E</span><span class="s2">7%A8%8B&#34;</span>
<span class="c1"># NOTE: the html_to_text=True option requires html2text to be installed</span>
<span class="n">documents</span> <span class="o">=</span> <span class="n">SimpleWebPageReader</span><span class="p">(</span><span class="n">html_to_text</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span>
    <span class="p">[</span><span class="n">target_url</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div><p>実行結果は、次のとおり。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">## Question:  中性子星合体におけるｒプロセスのメカニズムを教えて</span>
<span class="err">（中略）</span>
<span class="c1">## Answer: </span>
 <span class="err">中性子星合体の結果として、</span><span class="n">r過程が起こる可能性があります</span><span class="err">。</span>

<span class="err">中性子星は非常に高密度の状態で、その中で中性子捕獲が不安定な核が生成されます。この生成された中性子捕獲の不安定な核はベータ崩壊を繰り返しながら中性子をニッケル</span><span class="mi">56</span><span class="err">のような核種に取り込むことで、</span><span class="n">rプロセスと呼ばれる過程を起こします</span><span class="err">。</span>

<span class="c1">## Question:  銀河とブラックホールの共進化を説明して</span>
<span class="err">（中略）</span>
<span class="c1">## Answer: </span>
 <span class="err">コンテキスト情報に無い情報は回答に含めません。</span>

<span class="err">また、中性子星合体によるエネルギーの放出が最終的にブラックホールになるという情報はないので、この質問に対する回答は「分かりません」です。</span>
</code></pre></div><p>ｒプロセスに関する質問については、少し専門的な回答が得られたが、銀河とブラックホールの共進化に関する質問のように、埋め込みモデルに無い内容・概念を質問すると、答えられなくなる。</p>
<h2 id="今後">今後</h2>
<p>埋め込みモデルへの取り込みに関して、以下のような課題に挑戦していきたい。</p>
<ul>
<li>複数のWebページや特定のURL配下全体を埋め込みモデルに取り込む</li>
<li>PDFを埋め込みモデルに取り込む</li>
<li>テキスト、Web、PDFなど異なる形式のソースから埋め込みモデルに取り込む</li>
</ul>
<p>llamaindexの構造について理解を深め、RAGを使った回答の精度を高めていきたい。</p>

        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20240525_llamaindex_rag%2f&amp;text=LlamaIndex%e3%82%92%e4%bd%bf%e3%81%a3%e3%81%a6RAG%e3%82%92%e8%a9%a6%e3%81%99&amp;via=akenji3" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fakenji3.github.io%2fpost%2f20240525_llamaindex_rag%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20240525_llamaindex_rag%2f&amp;title=LlamaIndex%e3%82%92%e4%bd%bf%e3%81%a3%e3%81%a6RAG%e3%82%92%e8%a9%a6%e3%81%99" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20240525_llamaindex_rag%2f&amp;title=LlamaIndex%e3%82%92%e4%bd%bf%e3%81%a3%e3%81%a6RAG%e3%82%92%e8%a9%a6%e3%81%99" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20240525_llamaindex_rag%2f&amp;title=LlamaIndex%e3%82%92%e4%bd%bf%e3%81%a3%e3%81%a6RAG%e3%82%92%e8%a9%a6%e3%81%99" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fakenji3.github.io%2fpost%2f20240525_llamaindex_rag%2f&amp;description=LlamaIndex%e3%82%92%e4%bd%bf%e3%81%a3%e3%81%a6RAG%e3%82%92%e8%a9%a6%e3%81%99" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://akenji3.github.io/post/20240506_llamaserver/" data-toggle="tooltip" data-placement="top" title="Chatbot UIを試す">&larr; 前ページ</a>
            </li>
          
          
            <li class="next">
              <a href="https://akenji3.github.io/post/20240704_numpy_v2/" data-toggle="tooltip" data-placement="top" title="llama-cpp-python 〜 numpyバージョンアップの影響">次ページ &rarr;</a>
            </li>
          
        </ul>
      


      

    </div>
  </div>
</div>

      
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:akenji.1118@gmail.com" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://www.facebook.com/arai.kenji3" title="Facebook">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-facebook fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://github.com/akenji3" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/akenji3" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/kenji-arai-0547aa1a4" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            <a href="" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fas fa-circle fa-stack-2x"></i>
                <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              Kenji Arai
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2024
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://akenji3.github.io">akenji&#39;s lab</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          起動力に<a href="https://gohugo.io">Hugo v0.74.3</a> &nbsp;&bull;&nbsp; テーマに<a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a>に基づいている<a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="https://akenji3.github.io/js/main.js"></script>
<script src="https://akenji3.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script> renderMathInElement(document.body); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://akenji3.github.io/js/load-photoswipe.js"></script>








<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']]
  }
});
</script>


    
  </body>
</html>

